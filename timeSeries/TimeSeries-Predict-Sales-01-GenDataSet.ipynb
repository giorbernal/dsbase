{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('../datasets/predict-sales/sales_train.csv')\n",
    "items_df = pd.read_csv('../datasets/predict-sales/items.csv')\n",
    "test_df = pd.read_csv('../datasets/predict-sales/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.drop(labels=['date'],inplace=True,axis=1)\n",
    "sales_df = sales_df.reset_index()\n",
    "items_df.drop(labels=['item_name'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aux = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setPair(x, d):\n",
    "    i = str(x[0]) + '-' + str(x[1])\n",
    "    try:\n",
    "        return d[i]\n",
    "    except:\n",
    "        result = i\n",
    "        d[i] = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['ID_pair'] = sales_df[['shop_id','item_id']].apply(setPair, args=[dict_aux], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df.merge(items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_aux = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['ID_CAT_pair'] = sales_df[['shop_id','item_category_id']].apply(setPair, args=[dict_aux], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.to_csv('../datasets/predict-sales/sales_train_enriched.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv('../datasets/predict-sales/sales_train_enriched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.drop(labels=['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_th = 40\n",
    "sales_df_ensemble = sales_df[sales_df['item_category_id']>=40]\n",
    "sales_df_stacking = sales_df[sales_df['item_category_id']<40]\n",
    "print('ensemble size:',sales_df_ensemble.shape)\n",
    "print('stacking size:',sales_df_stacking.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some data from the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTimeSerie(df, sample, n):\n",
    "    for i in range(n):\n",
    "        shop_id = sample.iloc[i]['shop_id']\n",
    "        item_id = sample.iloc[i]['item_id']\n",
    "        id_df = df[(df['shop_id'] == shop_id) & (df['item_id'] == item_id)]\n",
    "        id_df_grouped = id_df[['date_block_num','item_cnt_day']].groupby('date_block_num').sum().reset_index()\n",
    "        plt.figure(figsize=[10,n*5])\n",
    "        plt.subplot(n,1,i+1)\n",
    "        plt.plot(id_df_grouped['date_block_num'], id_df_grouped['item_cnt_day'],'*-',)\n",
    "        plt.title(str(shop_id) + '-' + str(item_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "sample = sales_df_ensemble.sample(n=n_samples, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawTimeSerie(sales_df_ensemble, sample, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Preparing Data with FeatureTools (testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the FT process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_month_list = [6,7,8]\n",
    "month = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_months_df = sales_df[sales_df['date_block_num'].isin(prev_month_list)]\n",
    "sales_result_df = sales_df[sales_df['date_block_num'] == month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_months_df.drop(labels=['date_block_num','shop_id','item_id','item_category_id'], inplace=True, axis=1)\n",
    "sales_result_df.drop(labels=['date_block_num','shop_id','item_id','item_category_id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_months_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EntitySet Processing (Recommended by FeatureTools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate 3 tables that we must join later:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories Aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCatAgg(sales_months_df):\n",
    "    es = ft.EntitySet(id=\"prediction_sales\")\n",
    "    es = es.entity_from_dataframe(entity_id='sales',dataframe=sales_months_df, index='index')\n",
    "    es = es.normalize_entity(base_entity_id='sales',\n",
    "                         new_entity_id='idsCat',\n",
    "                         index='ID_CAT_pair')\n",
    "    feature_matrix_idsCat, feature_defs_idsCat = ft.dfs(entityset=es, target_entity='idsCat')\n",
    "    idsCat = feature_matrix_idsCat.reset_index()\n",
    "    idsCat_agg = idsCat[['ID_CAT_pair','SUM(sales.item_cnt_day)',\n",
    "                     'MEAN(sales.item_cnt_day)','MEAN(sales.item_price)',\n",
    "                     'STD(sales.item_cnt_day)','STD(sales.item_price)',\n",
    "                     'MAX(sales.item_cnt_day)','MAX(sales.item_price)',\n",
    "                     'MIN(sales.item_cnt_day)','MIN(sales.item_price)',\n",
    "                     'SKEW(sales.item_cnt_day)','SKEW(sales.item_price)'\n",
    "                    ]]\n",
    "    idsCat_agg.columns = ['ID_CAT_pair','sum_shop_cat_sales',\n",
    "                      'mean_shop_cat_day','mean_shop_cat_item_price',\n",
    "                      'std_shop_cat_day','std_shop_cat_item_price',\n",
    "                      'max_shop_cat_day','max_shop_cat_item_price',\n",
    "                      'min_shop_cat_day','min_shop_cat_item_price',\n",
    "                      'skew_shop_cat_day','skew_shop_cat_item_price',\n",
    "                     ]\n",
    "    return idsCat_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsCat = getCatAgg(sales_months_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsCat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsCat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemAgg(sales_months_df):\n",
    "    es = ft.EntitySet(id=\"prediction_sales\")\n",
    "    es = es.entity_from_dataframe(entity_id='sales',dataframe=sales_months_df, index='index')\n",
    "    es = es.normalize_entity(base_entity_id='sales',\n",
    "                         new_entity_id='ids',\n",
    "                         index='ID_pair',\n",
    "                         additional_variables=['ID_CAT_pair'])\n",
    "    feature_matrix_ids, feature_defs_ids = ft.dfs(entityset=es, target_entity='ids')\n",
    "    ids = feature_matrix_ids.reset_index()\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = getItemAgg(sales_months_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetAgg(sales_result_df):\n",
    "    es = ft.EntitySet(id=\"target_sales\")\n",
    "    es = es.entity_from_dataframe(entity_id='sales',dataframe=sales_result_df, index='index')\n",
    "    es = es.normalize_entity(base_entity_id='sales',\n",
    "                         new_entity_id='target',\n",
    "                         index='ID_pair',\n",
    "                         additional_variables=['ID_CAT_pair'])\n",
    "    feature_matrix_target, feature_defs_target = ft.dfs(entityset=es, target_entity='target')\n",
    "    target = feature_matrix_target.reset_index()\n",
    "    target_agg = target[['ID_pair','ID_CAT_pair','SUM(sales.item_cnt_day)']]\n",
    "    target_agg.columns = ['ID_pair','ID_CAT_pair','total_sales']\n",
    "    return target_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = getTargetAgg(sales_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join of the 3 previous tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joinThreeParts(ids, idsCat, target):\n",
    "    df = ids.merge(right=idsCat,on='ID_CAT_pair',how='left').merge(right=target,on='ID_pair',how='outer')\n",
    "    df.drop(labels=['ID_CAT_pair_x'], inplace=True, axis=1)\n",
    "    df.columns = ['ID_pair', 'SUM(sales.item_price)', 'SUM(sales.item_cnt_day)',\n",
    "       'STD(sales.item_price)', 'STD(sales.item_cnt_day)',\n",
    "       'MAX(sales.item_price)', 'MAX(sales.item_cnt_day)',\n",
    "       'SKEW(sales.item_price)', 'SKEW(sales.item_cnt_day)',\n",
    "       'MIN(sales.item_price)', 'MIN(sales.item_cnt_day)',\n",
    "       'MEAN(sales.item_price)', 'MEAN(sales.item_cnt_day)', 'COUNT(sales)',\n",
    "       'sum_shop_cat_sales', 'mean_shop_cat_day', 'mean_shop_cat_item_price',\n",
    "       'std_shop_cat_day', 'std_shop_cat_item_price', 'max_shop_cat_day',\n",
    "       'max_shop_cat_item_price', 'min_shop_cat_day',\n",
    "       'min_shop_cat_item_price', 'skew_shop_cat_day',\n",
    "       'skew_shop_cat_item_price', 'ID_CAT_pair', 'total_sales']\n",
    "    df_with_ids = df[~df['SUM(sales.item_price)'].isna()]\n",
    "    df_without_ids = df[df['SUM(sales.item_price)'].isna()]\n",
    "    df_without_ids.drop(labels=['sum_shop_cat_sales', 'mean_shop_cat_day', 'mean_shop_cat_item_price',\n",
    "       'std_shop_cat_day', 'std_shop_cat_item_price', 'max_shop_cat_day',\n",
    "       'max_shop_cat_item_price', 'min_shop_cat_day',\n",
    "       'min_shop_cat_item_price', 'skew_shop_cat_day',\n",
    "       'skew_shop_cat_item_price'], inplace=True, axis=1)\n",
    "    df_without_ids_enriched = df_without_ids.merge(right=idsCat, on='ID_CAT_pair', how='left')\n",
    "    df_without_ids_enriched_sorted = df_without_ids_enriched[['ID_pair','SUM(sales.item_price)','SUM(sales.item_cnt_day)','STD(sales.item_price)','STD(sales.item_cnt_day)','MAX(sales.item_price)','MAX(sales.item_cnt_day)','SKEW(sales.item_price)','SKEW(sales.item_cnt_day)','MIN(sales.item_price)','MIN(sales.item_cnt_day)','MEAN(sales.item_price)','MEAN(sales.item_cnt_day)','COUNT(sales)','sum_shop_cat_sales','mean_shop_cat_day','mean_shop_cat_item_price','std_shop_cat_day','std_shop_cat_item_price','max_shop_cat_day','max_shop_cat_item_price','min_shop_cat_day','min_shop_cat_item_price','skew_shop_cat_day','skew_shop_cat_item_price','ID_CAT_pair','total_sales']]\n",
    "    df_completed = pd.concat(objs=[df_with_ids,df_without_ids_enriched_sorted], axis=0)\n",
    "    df_completed.drop(labels=['ID_CAT_pair'], inplace=True, axis=1)\n",
    "    return df_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(~df_joined.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the DataSet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = sales_df['date_block_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFeatures(sales_df, months_feature, month_target, calculateTarget=True):\n",
    "    print('features window:',months_feature,', target:',month_target)\n",
    "    sales_months_df = sales_df[sales_df['date_block_num'].isin(months_feature)]\n",
    "    sales_result_df = sales_df[sales_df['date_block_num'] == month_target]\n",
    "    sales_months_df.drop(labels=['date_block_num','shop_id','item_id','item_category_id'], inplace=True, axis=1)\n",
    "    sales_result_df.drop(labels=['date_block_num','shop_id','item_id','item_category_id'], inplace=True, axis=1)\n",
    "    \n",
    "    idsCat = getCatAgg(sales_months_df)\n",
    "    ids = getItemAgg(sales_months_df)\n",
    "    target = getTargetAgg(sales_result_df)\n",
    "    target.head(3)\n",
    "    \n",
    "    joined = joinThreeParts(ids, idsCat, target)\n",
    "    \n",
    "    # Insert the slot component for correlation purposes\n",
    "    joined['slot'] = joined['COUNT(sales)'].apply(lambda x: months_feature[-1])\n",
    "    return joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slidingWindow(sales_df, size, slots):\n",
    "    df_final = pd.DataFrame()\n",
    "    for index in range(size,slots):\n",
    "        features_target = generateFeatures(sales_df, np.arange(index-size,index),index)\n",
    "        # TODO stack dataset\n",
    "        df_final = pd.concat([df_final,features_target], axis=0) \n",
    "    # TODO return completed dataset\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstest = slidingWindow(sales_df_ensemble, 3,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(~dstest.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstest[dstest['ID_pair']=='10-1008']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstest[dstest['slot']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [3,6,12,18,25,32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1A = slidingWindow(sales_df_ensemble, windows[0], slots)\n",
    "dataset1B = slidingWindow(sales_df_stacking, windows[0], slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1A.to_csv('../datasets/predict-sales/dataset1A.csv')\n",
    "dataset1B.to_csv('../datasets/predict-sales/dataset1B.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2A = slidingWindow(sales_df_ensemble, windows[1], slots)\n",
    "dataset2B = slidingWindow(sales_df_stacking, windows[1], slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2A.to_csv('datasets/predict-sales/dataset2A.csv')\n",
    "dataset2B.to_csv('datasets/predict-sales/dataset2B.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3A = slidingWindow(sales_df_ensemble, windows[2], slots)\n",
    "dataset3B = slidingWindow(sales_df_stacking, windows[2], slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3A.to_csv('../datasets/predict-sales/dataset3A.csv')\n",
    "dataset3B.to_csv('../datasets/predict-sales/dataset3B.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4A = slidingWindow(sales_df_ensemble, windows[3], slots)\n",
    "dataset4B = slidingWindow(sales_df_stacking, windows[3], slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4A.to_csv('../datasets/predict-sales/dataset4A.csv')\n",
    "dataset4B.to_csv('../datasets/predict-sales/dataset4B.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5A = slidingWindow(sales_df_ensemble, windows[4],slots)\n",
    "dataset5B = slidingWindow(sales_df_stacking, windows[4],slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset5A.to_csv('../datasets/predict-sales/dataset5A.csv')\n",
    "dataset5B.to_csv('../datasets/predict-sales/dataset5B.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6A = slidingWindow(sales_df_ensemble, windows[5],slots)\n",
    "dataset6B = slidingWindow(sales_df_stacking, windows[5],slots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset6A.to_csv('../datasets/predict-sales/dataset6A.csv')\n",
    "dataset6B.to_csv('../datasets/predict-sales/dataset6B.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Case! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
