{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dsbase.ModelDSBase import ModelDSBaseWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsbase.models.regression.LightGradientBoostingRegressionDSBase import LightGradientBoostingRegressionDSBaseModel\n",
    "from dsbase.models.regression.LightGradientBoostingRegressionDSBase import LightGradientBoostingRegressionDSBaseModelParamsToMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/predict-sales/dataset1A.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataset(df):\n",
    "    # Removing targets without evidence\n",
    "    df_cleaned = df[~df['date_block_num'].isna()]\n",
    "    \n",
    "    # Imputing features\n",
    "    df_cleaned['STD(sales.item_cnt_day)_imputed'] = df_cleaned['STD(sales.item_cnt_day)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['STD(sales.item_price)_imputed'] = df_cleaned['STD(sales.item_price)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['STD(sales.item_cnt_day)_na_indicator'] = df_cleaned['STD(sales.item_cnt_day)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['STD(sales.item_price)_na_indicator'] = df_cleaned['STD(sales.item_price)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['SKEW(sales.item_cnt_day)_imputed'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['SKEW(sales.item_price)_imputed'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['SKEW(sales.item_cnt_day)_na_indicator'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['SKEW(sales.item_price)_na_indicator'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['skew_shop_cat_day_imputed'] = df_cleaned['skew_shop_cat_day'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['skew_shop_cat_item_price_imputed'] = df_cleaned['skew_shop_cat_item_price'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['skew_shop_cat_day_na_indicator'] = df_cleaned['skew_shop_cat_day'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['skew_shop_cat_item_price_na_indicator'] = df_cleaned['skew_shop_cat_item_price'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned.drop(labels=['STD(sales.item_cnt_day)','STD(sales.item_price)',\n",
    "                            'SKEW(sales.item_cnt_day)','SKEW(sales.item_price)',\n",
    "                            'skew_shop_cat_day','skew_shop_cat_item_price'\n",
    "                           ], inplace=True, axis=1)\n",
    "    \n",
    "    # imputing target\n",
    "    df_cleaned['target_imputed'] = df_cleaned['target'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned.drop(labels=['target'], inplace=True, axis=1)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = cleanDataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned.drop(labels=['target_imputed'], axis=1).values\n",
    "y = df_cleaned['target_imputed'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple case (Just first test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=31, n_estimators=100, learning_rate=0.1,num_leaves=31, subsample_for_bin=200000, reg_alpha=0, reg_lambda=0)\n",
    "#params = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=20, n_estimators=70, learning_rate=0.1, num_leaves=31, subsample_for_bin=1000000, reg_alpha=100000, reg_lambda=100)\n",
    "#lgbr = ModelDSBaseWrapper('LGBR',X_train,y_train,X_test, y_test,[20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],LightGradientBoostingRegressionDSBaseModel,params)\n",
    "lgbr = ModelDSBaseWrapper('LGBR',X_train,y_train,X_test, y_test,[100],LightGradientBoostingRegressionDSBaseModel,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lclgdbr=lgbr.getLearningCurves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lclgdbr[0,:],'b',lclgdbr[1,:],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbr.getScore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation Optimization Method for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time requieredd for a 5-fold cross validation process: 2 min "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsbase.SearchOptimumParams import evaluateParams, randomElement, showSearchOptimumHyperParametersReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth=[10,20,30,40,50,60,70,80,90,100]\n",
    "n_estimators=[70,80,90,100,110,120,130,140,150]\n",
    "learning_rate=[0.01,0.03,0.1,0.3,1]\n",
    "subsample_for_bin=[75000,100000,150000,200000,500000,1000000,1300000,2000000,2300000]\n",
    "num_leaves=[7,15,31,63,127]\n",
    "reg_alpha=[0,50000,75000,90000,100000,120000]\n",
    "reg_lambda=[0,20,50,100,150,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tries = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for i in range(num_tries):\n",
    "    p = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=randomElement(max_depth),\n",
    "                                                                   n_estimators=randomElement(n_estimators),\n",
    "                                                                   learning_rate=randomElement(learning_rate),\n",
    "                                                                   subsample_for_bin=randomElement(subsample_for_bin),\n",
    "                                                                   reg_alpha=randomElement(reg_alpha),\n",
    "                                                                   reg_lambda=randomElement(reg_lambda))\n",
    "    params.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tries = evaluateParams(X, y, 5, LightGradientBoostingRegressionDSBaseModel, 'LGBR', params, num_tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showSearchOptimumHyperParametersReport(tries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processModel(databaseName, modelName):\n",
    "    df = pd.read_csv('../datasets/predict-sales/' + databaseName + '.csv')\n",
    "    df.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "    df_cleaned = cleanDataset(df)\n",
    "    X = df_cleaned.drop(labels=['target_imputed'], axis=1).values\n",
    "    y = df_cleaned['target_imputed'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    params = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=31, n_estimators=100, learning_rate=0.1,num_leaves=31, subsample_for_bin=200000, reg_alpha=0, reg_lambda=0)\n",
    "    lgbr = ModelDSBaseWrapper(modelName,X_train,y_train,X_test, y_test,[100],LightGradientBoostingRegressionDSBaseModel,params)\n",
    "    lgbr.train()\n",
    "    lclgdbr=lgbr.getLearningCurves()\n",
    "    print('Score for',modelName,lgbr.getScore())\n",
    "    return lgbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 (LightGB for each 1/2 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = processModel('dataset1A','model1')\n",
    "model1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = processModel('dataset2A','model2')\n",
    "model2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = processModel('dataset3A','model3')\n",
    "model3.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = processModel('dataset4A','model4')\n",
    "model4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = processModel('dataset5A','model5')\n",
    "model5.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = processModel('dataset6A','model6')\n",
    "model6.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 (NN for the 1/2 processed dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating 2º dataset processing datasetXB in the previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Case! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
