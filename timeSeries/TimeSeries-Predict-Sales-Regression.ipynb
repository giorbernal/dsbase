{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dsbase.ModelDSBase import ModelDSBaseWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsbase.models.regression.LightGradientBoostingRegressionDSBase import LightGradientBoostingRegressionDSBaseModel\n",
    "from dsbase.models.regression.LightGradientBoostingRegressionDSBase import LightGradientBoostingRegressionDSBaseModelParamsToMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = pd.read_csv('../datasets/predict-sales/dataset1A.csv')\n",
    "dfB = pd.read_csv('../datasets/predict-sales/dataset1B.csv')\n",
    "df = pd.concat([dfA,dfB], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataset(df):\n",
    "    # Removing targets without evidence\n",
    "    df_cleaned = df[~df['date_block_num'].isna()]\n",
    "    \n",
    "    # Imputing features\n",
    "    df_cleaned['STD(sales.item_cnt_day)_imputed'] = df_cleaned['STD(sales.item_cnt_day)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['STD(sales.item_price)_imputed'] = df_cleaned['STD(sales.item_price)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['STD(sales.item_cnt_day)_na_indicator'] = df_cleaned['STD(sales.item_cnt_day)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['STD(sales.item_price)_na_indicator'] = df_cleaned['STD(sales.item_price)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['SKEW(sales.item_cnt_day)_imputed'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['SKEW(sales.item_price)_imputed'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['SKEW(sales.item_cnt_day)_na_indicator'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['SKEW(sales.item_price)_na_indicator'] = df_cleaned['SKEW(sales.item_cnt_day)'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['skew_shop_cat_day_imputed'] = df_cleaned['skew_shop_cat_day'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['skew_shop_cat_item_price_imputed'] = df_cleaned['skew_shop_cat_item_price'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned['skew_shop_cat_day_na_indicator'] = df_cleaned['skew_shop_cat_day'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned['skew_shop_cat_item_price_na_indicator'] = df_cleaned['skew_shop_cat_item_price'].apply(lambda x: 1 if (math.isnan(x)) else 0)\n",
    "    df_cleaned.drop(labels=['STD(sales.item_cnt_day)','STD(sales.item_price)',\n",
    "                            'SKEW(sales.item_cnt_day)','SKEW(sales.item_price)',\n",
    "                            'skew_shop_cat_day','skew_shop_cat_item_price'\n",
    "                           ], inplace=True, axis=1)\n",
    "    \n",
    "    # imputing target\n",
    "    df_cleaned['target_imputed'] = df_cleaned['target'].apply(lambda x: 0 if (math.isnan(x)) else x)\n",
    "    df_cleaned.drop(labels=['target'], inplace=True, axis=1)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = cleanDataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cleaned.drop(labels=['target_imputed'], axis=1).values\n",
    "y = df_cleaned['target_imputed'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple case (Just first test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=31, n_estimators=100, learning_rate=0.1,num_leaves=31, subsample_for_bin=200000, reg_alpha=0, reg_lambda=0)\n",
    "params = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=31, n_estimators=100, learning_rate=0.1,num_leaves=31, subsample_for_bin=200000, reg_alpha=3000, reg_lambda=10)\n",
    "#params = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=20, n_estimators=70, learning_rate=0.1, num_leaves=31, subsample_for_bin=1000000, reg_alpha=100000, reg_lambda=100)\n",
    "lgbr = ModelDSBaseWrapper('LGBR',X_train,y_train,X_test, y_test,[20,30,40,50,60,70,80,90,100],LightGradientBoostingRegressionDSBaseModel,params)\n",
    "#lgbr = ModelDSBaseWrapper('LGBR',X_train,y_train,X_test, y_test,[100],LightGradientBoostingRegressionDSBaseModel,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lclgdbr=lgbr.getLearningCurves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lclgdbr[0,:],'b',lclgdbr[1,:],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbr.getScore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not do it finally, for the moment! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processModel(databaseName, modelName):\n",
    "    dfA = pd.read_csv('../datasets/predict-sales/' + databaseName + 'A.csv')\n",
    "    dfB = pd.read_csv('../datasets/predict-sales/' + databaseName + 'B.csv')\n",
    "    df = pd.concat([dfA,dfB], axis=0)\n",
    "    df.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "    df_cleaned = cleanDataset(df)\n",
    "    X = df_cleaned.drop(labels=['target_imputed'], axis=1).values\n",
    "    y = df_cleaned['target_imputed'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    params = LightGradientBoostingRegressionDSBaseModelParamsToMap(max_depth=31, n_estimators=100, learning_rate=0.1,num_leaves=31, subsample_for_bin=200000, reg_alpha=0, reg_lambda=0)\n",
    "    lgbr = ModelDSBaseWrapper(modelName,X_train,y_train,X_test, y_test,[100],LightGradientBoostingRegressionDSBaseModel,params)\n",
    "    lgbr.train()\n",
    "    lclgdbr=lgbr.getLearningCurves()\n",
    "    print('Score for',modelName,lgbr.getScore())\n",
    "    return lgbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 (LightGB for each 1/2 dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = processModel('dataset1','model1')\n",
    "model1.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = processModel('dataset2','model2')\n",
    "model2.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = processModel('dataset3','model3')\n",
    "model3.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = processModel('dataset4','model4')\n",
    "model4.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = processModel('dataset5','model5')\n",
    "model5.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = processModel('dataset6','model6')\n",
    "model6.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 (NN for the 1/2 processed dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult to generate the dataset ... !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating 2º dataset processing datasetXB in the previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Case! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
