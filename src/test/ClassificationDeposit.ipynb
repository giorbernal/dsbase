{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification: Deposit Bank - Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('../main/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from ModelDSBase import ModelDSBaseWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../datasets/deposit_ml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_r = pd.read_csv('../../datasets/deposit_ml_reduced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(labels='y', axis=1).values\n",
    "y = df['y'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_r = df_r.drop(labels='y', axis=1).values\n",
    "y_r = df_r['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Binary Classifier (It takes too much time, although the results are quite good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from SVMClassificationDSBase import SVMClassificationDSBaseModelParamsToMap\n",
    "from SVMClassificationDSBase import SVMClassificationDSBaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = SVMClassificationDSBaseModelParamsToMap()\n",
    "svmc = ModelDSBaseWrapper('SVM',X,y,[5,10,15],0.3,SVMClassificationDSBaseModel,params,splitter=train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lcsvmc = svmc.getLearningCurves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(lcsvmc[0,:],'b',lcsvmc[1,:],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmc.getScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recoveredSvmc = SVMClassificationDSBaseModel('SVM2',None,None,None,None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recoveredSvmc.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recoveredSvmc.predict(X[510:515,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y[510:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recoveredSvmc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest Classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RandomForestClassificationDSBase import RandomForestClassificationDSBaseModel\n",
    "from RandomForestClassificationDSBase import RandomForestClassificationDSBaseModelParamsToMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size:(45211, 52)\n",
      "y size:(45211,)\n",
      "initiating model RF0. RandomForestClassification\n",
      "initiating model RF1. RandomForestClassification\n",
      "initiating model RF2. RandomForestClassification\n",
      "initiating model RF3. RandomForestClassification\n",
      "initiating model RF4. RandomForestClassification\n",
      "initiating model RF5. RandomForestClassification\n",
      "initiating model RF6. RandomForestClassification\n"
     ]
    }
   ],
   "source": [
    "params = RandomForestClassificationDSBaseModelParamsToMap(100,15)\n",
    "rfc = ModelDSBaseWrapper('RF',X,y,[70,75,80,85,90,95,100],0.3,RandomForestClassificationDSBaseModel,params,splitter=train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model RF0. RandomForestClassification\n",
      "training model RF1. RandomForestClassification\n",
      "training model RF2. RandomForestClassification\n",
      "training model RF3. RandomForestClassification\n",
      "training model RF4. RandomForestClassification\n",
      "training model RF5. RandomForestClassification\n",
      "training model RF6. RandomForestClassification\n"
     ]
    }
   ],
   "source": [
    "rfc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lcrfc = rfc.getLearningCurves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a32f5a240>,\n",
       " <matplotlib.lines.Line2D at 0x1a32f5a6d8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a25484320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lcrfc[0,:],'b',lcrfc[1,:],'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite Overfitting!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91234149218519611"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.getScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model: model_persistance/RandomForestClassification_RF6.sav\n"
     ]
    }
   ],
   "source": [
    "rfc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating empty model RF6. RandomForestClassification\n"
     ]
    }
   ],
   "source": [
    "recoveredRfc = RandomForestClassificationDSBaseModel('RF6',None,None,None,None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model: model_persistance/RandomForestClassification_RF6.sav\n"
     ]
    }
   ],
   "source": [
    "recoveredRfc.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting model RF6. RandomForestClassification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recoveredRfc.predict(X[510:515,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[510:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting model RF6. RandomForestClassification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95     11966\n",
      "          1       0.71      0.44      0.54      1598\n",
      "\n",
      "avg / total       0.90      0.91      0.90     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(rfc.model.y_test,rfc.predict(rfc.model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting model RF6. RandomForestClassification\n",
      "[[11676   290]\n",
      " [  899   699]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(rfc.model.y_test,rfc.predict(rfc.model.X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ada Boosting Classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AdaBoostClassificationDSBase import AdaBoostClassificationDSBaseModelParamsToMap\n",
    "from AdaBoostClassificationDSBase import AdaBoostClassificationDSBaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size:(45211, 52)\n",
      "y size:(45211,)\n",
      "initiating model AB0. AdaBoostClassification\n",
      "initiating model AB1. AdaBoostClassification\n",
      "initiating model AB2. AdaBoostClassification\n",
      "initiating model AB3. AdaBoostClassification\n",
      "initiating model AB4. AdaBoostClassification\n",
      "initiating model AB5. AdaBoostClassification\n",
      "initiating model AB6. AdaBoostClassification\n"
     ]
    }
   ],
   "source": [
    "params = AdaBoostClassificationDSBaseModelParamsToMap(100,1.0)\n",
    "abc = ModelDSBaseWrapper('AB',X,y,[70,75,80,85,90,95,100],0.3,AdaBoostClassificationDSBaseModel,params,splitter=train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model AB0. AdaBoostClassification\n",
      "training model AB1. AdaBoostClassification\n",
      "training model AB2. AdaBoostClassification\n",
      "training model AB3. AdaBoostClassification\n",
      "training model AB4. AdaBoostClassification\n",
      "training model AB5. AdaBoostClassification\n",
      "training model AB6. AdaBoostClassification\n"
     ]
    }
   ],
   "source": [
    "abc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lcabc = abc.getLearningCurves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a32305320>,\n",
       " <matplotlib.lines.Line2D at 0x1a32305470>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0ohCX0QkjSj0RUTSyP8DTRM+TT7kuNIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3252d048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lcabc[0,:],'b',lcabc[1,:],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90718077263344143"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc.getScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model: model_persistance/AdaBoostClassification_AB6.sav\n"
     ]
    }
   ],
   "source": [
    "abc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating empty model AB6. AdaBoostClassification\n"
     ]
    }
   ],
   "source": [
    "recoveredAbc = AdaBoostClassificationDSBaseModel('AB6',None,None,None,None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model: model_persistance/AdaBoostClassification_AB6.sav\n"
     ]
    }
   ],
   "source": [
    "recoveredAbc.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting model AB6. AdaBoostClassification\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recoveredAbc.predict(X[510:515,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[510:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting model AB6. AdaBoostClassification\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95     11966\n",
      "          1       0.67      0.42      0.52      1598\n",
      "\n",
      "avg / total       0.90      0.91      0.90     13564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(abc.model.y_test,abc.predict(abc.model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting model AB6. AdaBoostClassification\n",
      "[[11629   337]\n",
      " [  922   676]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(abc.model.y_test,abc.predict(abc.model.X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Classification (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DNNClassificationKerasDSBase import DNNClassificationKerasDSBaseParamsToMap\n",
    "from DNNClassificationKerasDSBase import DNNClassificationKerasDSBaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size:(45211, 52)\n",
      "y size:(45211,)\n",
      "initiating model DNNKC0. DNNClassificationKeras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating model DNNKC1. DNNClassificationKeras\n",
      "initiating model DNNKC2. DNNClassificationKeras\n",
      "initiating model DNNKC3. DNNClassificationKeras\n",
      "initiating model DNNKC4. DNNClassificationKeras\n",
      "initiating model DNNKC5. DNNClassificationKeras\n",
      "initiating model DNNKC6. DNNClassificationKeras\n"
     ]
    }
   ],
   "source": [
    "params = DNNClassificationKerasDSBaseParamsToMap(layers=[40,20,10,5], alpha=1e-2, beta1=0.9, beta2=0.999, epsilon=1e-9, batch_size=64, epochs=150)\n",
    "dnnkc = ModelDSBaseWrapper('DNNKC',X,y,[70,75,80,85,90,95,100],0.3,DNNClassificationKerasDSBaseModel,params,splitter=train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "22152/22152 [==============================] - 2s 69us/step - loss: 0.2317 - acc: 0.9420\n",
      "Epoch 2/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.2204 - acc: 0.9420\n",
      "Epoch 3/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.1538 - acc: 0.9428\n",
      "Epoch 4/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1274 - acc: 0.9468\n",
      "Epoch 5/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.1202 - acc: 0.9476\n",
      "Epoch 6/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1179 - acc: 0.9466\n",
      "Epoch 7/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.1148 - acc: 0.9488\n",
      "Epoch 8/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1130 - acc: 0.9498\n",
      "Epoch 9/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1126 - acc: 0.9484\n",
      "Epoch 10/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1107 - acc: 0.9486\n",
      "Epoch 11/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1086 - acc: 0.9495\n",
      "Epoch 12/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1085 - acc: 0.9500\n",
      "Epoch 13/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1074 - acc: 0.9509\n",
      "Epoch 14/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1054 - acc: 0.9513\n",
      "Epoch 15/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1059 - acc: 0.9510\n",
      "Epoch 16/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1031 - acc: 0.9520\n",
      "Epoch 17/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1027 - acc: 0.9534\n",
      "Epoch 18/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1023 - acc: 0.9529\n",
      "Epoch 19/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1018 - acc: 0.9542\n",
      "Epoch 20/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.1008 - acc: 0.9531\n",
      "Epoch 21/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0992 - acc: 0.9541\n",
      "Epoch 22/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0994 - acc: 0.9547\n",
      "Epoch 23/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0979 - acc: 0.9552\n",
      "Epoch 24/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0967 - acc: 0.9548\n",
      "Epoch 25/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0952 - acc: 0.9566\n",
      "Epoch 26/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0961 - acc: 0.9564\n",
      "Epoch 27/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0938 - acc: 0.9570\n",
      "Epoch 28/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0945 - acc: 0.9568\n",
      "Epoch 29/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0926 - acc: 0.9577\n",
      "Epoch 30/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0918 - acc: 0.9573\n",
      "Epoch 31/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0922 - acc: 0.9584\n",
      "Epoch 32/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0910 - acc: 0.9590\n",
      "Epoch 33/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0897 - acc: 0.9581\n",
      "Epoch 34/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0896 - acc: 0.9590\n",
      "Epoch 35/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0892 - acc: 0.9591\n",
      "Epoch 36/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0894 - acc: 0.9596\n",
      "Epoch 37/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0892 - acc: 0.9591\n",
      "Epoch 38/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0871 - acc: 0.9596\n",
      "Epoch 39/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0883 - acc: 0.9597\n",
      "Epoch 40/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0860 - acc: 0.9609\n",
      "Epoch 41/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0874 - acc: 0.9605\n",
      "Epoch 42/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0868 - acc: 0.9599\n",
      "Epoch 43/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0852 - acc: 0.9609\n",
      "Epoch 44/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0838 - acc: 0.9608\n",
      "Epoch 45/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0840 - acc: 0.9617\n",
      "Epoch 46/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0838 - acc: 0.9618\n",
      "Epoch 47/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0828 - acc: 0.9620\n",
      "Epoch 48/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0831 - acc: 0.9625\n",
      "Epoch 49/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0821 - acc: 0.9629\n",
      "Epoch 50/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0819 - acc: 0.9638\n",
      "Epoch 51/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0820 - acc: 0.9626\n",
      "Epoch 52/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0809 - acc: 0.9633\n",
      "Epoch 53/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0801 - acc: 0.9632\n",
      "Epoch 54/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0788 - acc: 0.9643\n",
      "Epoch 55/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0799 - acc: 0.9634\n",
      "Epoch 56/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0800 - acc: 0.9629\n",
      "Epoch 57/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0793 - acc: 0.9642\n",
      "Epoch 58/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0785 - acc: 0.9637\n",
      "Epoch 59/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0792 - acc: 0.9642\n",
      "Epoch 60/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0782 - acc: 0.9643\n",
      "Epoch 61/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0767 - acc: 0.9648\n",
      "Epoch 62/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0761 - acc: 0.9656\n",
      "Epoch 63/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0781 - acc: 0.9651\n",
      "Epoch 64/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0756 - acc: 0.9652\n",
      "Epoch 65/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0752 - acc: 0.9662\n",
      "Epoch 66/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0762 - acc: 0.9656\n",
      "Epoch 67/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0744 - acc: 0.9668\n",
      "Epoch 68/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0751 - acc: 0.9661\n",
      "Epoch 69/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0759 - acc: 0.9652\n",
      "Epoch 70/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0737 - acc: 0.9664\n",
      "Epoch 71/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0743 - acc: 0.9671\n",
      "Epoch 72/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0739 - acc: 0.9664\n",
      "Epoch 73/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0720 - acc: 0.9662\n",
      "Epoch 74/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0732 - acc: 0.9654\n",
      "Epoch 75/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0731 - acc: 0.9671\n",
      "Epoch 76/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0728 - acc: 0.9670\n",
      "Epoch 77/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0717 - acc: 0.9671\n",
      "Epoch 78/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0733 - acc: 0.9661\n",
      "Epoch 79/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0707 - acc: 0.9677\n",
      "Epoch 80/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0717 - acc: 0.9677\n",
      "Epoch 81/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0737 - acc: 0.9669\n",
      "Epoch 82/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0699 - acc: 0.9672\n",
      "Epoch 83/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0699 - acc: 0.9670\n",
      "Epoch 84/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0692 - acc: 0.9677\n",
      "Epoch 85/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0701 - acc: 0.9665\n",
      "Epoch 86/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0720 - acc: 0.9677\n",
      "Epoch 87/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0684 - acc: 0.9681\n",
      "Epoch 88/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0686 - acc: 0.9679\n",
      "Epoch 89/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0716 - acc: 0.9679\n",
      "Epoch 90/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0696 - acc: 0.9675\n",
      "Epoch 91/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0678 - acc: 0.9682\n",
      "Epoch 92/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0677 - acc: 0.9689\n",
      "Epoch 93/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0685 - acc: 0.9686\n",
      "Epoch 94/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0682 - acc: 0.9688\n",
      "Epoch 95/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0656 - acc: 0.9686\n",
      "Epoch 96/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0681 - acc: 0.9681\n",
      "Epoch 97/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0670 - acc: 0.9690\n",
      "Epoch 98/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0667 - acc: 0.9684\n",
      "Epoch 99/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0667 - acc: 0.9683\n",
      "Epoch 100/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0666 - acc: 0.9686\n",
      "Epoch 101/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0676 - acc: 0.9685\n",
      "Epoch 102/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0651 - acc: 0.9688\n",
      "Epoch 103/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0667 - acc: 0.9683\n",
      "Epoch 104/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0659 - acc: 0.9688\n",
      "Epoch 105/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0660 - acc: 0.9697\n",
      "Epoch 106/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0662 - acc: 0.9691\n",
      "Epoch 107/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0645 - acc: 0.9695\n",
      "Epoch 108/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0663 - acc: 0.9683\n",
      "Epoch 109/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0658 - acc: 0.9682\n",
      "Epoch 110/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0654 - acc: 0.9686\n",
      "Epoch 111/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0658 - acc: 0.9686\n",
      "Epoch 112/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0641 - acc: 0.9695\n",
      "Epoch 113/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0658 - acc: 0.9687\n",
      "Epoch 114/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0656 - acc: 0.9690\n",
      "Epoch 115/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0659 - acc: 0.9682\n",
      "Epoch 116/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0631 - acc: 0.9696\n",
      "Epoch 117/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0636 - acc: 0.9701\n",
      "Epoch 118/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0634 - acc: 0.9707\n",
      "Epoch 119/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0651 - acc: 0.9696\n",
      "Epoch 120/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0639 - acc: 0.9692\n",
      "Epoch 121/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0624 - acc: 0.9711\n",
      "Epoch 122/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0639 - acc: 0.9699\n",
      "Epoch 123/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0627 - acc: 0.9709\n",
      "Epoch 124/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0630 - acc: 0.9701\n",
      "Epoch 125/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0625 - acc: 0.9702\n",
      "Epoch 126/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0649 - acc: 0.9696\n",
      "Epoch 127/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0621 - acc: 0.9700\n",
      "Epoch 128/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0614 - acc: 0.9710\n",
      "Epoch 129/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0637 - acc: 0.9702\n",
      "Epoch 130/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0633 - acc: 0.9709\n",
      "Epoch 131/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0618 - acc: 0.9705\n",
      "Epoch 132/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0607 - acc: 0.9721\n",
      "Epoch 133/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0613 - acc: 0.9712\n",
      "Epoch 134/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0610 - acc: 0.9713\n",
      "Epoch 135/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0640 - acc: 0.9705\n",
      "Epoch 136/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0610 - acc: 0.9714\n",
      "Epoch 137/150\n",
      "22152/22152 [==============================] - 1s 29us/step - loss: 0.0605 - acc: 0.9711\n",
      "Epoch 138/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0608 - acc: 0.9720\n",
      "Epoch 139/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0613 - acc: 0.9725\n",
      "Epoch 140/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0602 - acc: 0.9717\n",
      "Epoch 141/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0617 - acc: 0.9711\n",
      "Epoch 142/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0617 - acc: 0.9706\n",
      "Epoch 143/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0594 - acc: 0.9714\n",
      "Epoch 144/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0600 - acc: 0.9727\n",
      "Epoch 145/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0604 - acc: 0.9720\n",
      "Epoch 146/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0618 - acc: 0.9708\n",
      "Epoch 147/150\n",
      "22152/22152 [==============================] - 1s 27us/step - loss: 0.0592 - acc: 0.9723\n",
      "Epoch 148/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0600 - acc: 0.9718\n",
      "Epoch 149/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0585 - acc: 0.9725\n",
      "Epoch 150/150\n",
      "22152/22152 [==============================] - 1s 28us/step - loss: 0.0592 - acc: 0.9721\n",
      "Epoch 1/150\n",
      "23735/23735 [==============================] - 1s 42us/step - loss: 0.2382 - acc: 0.9367\n",
      "Epoch 2/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1745 - acc: 0.9368\n",
      "Epoch 3/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1391 - acc: 0.9410\n",
      "Epoch 4/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1326 - acc: 0.9432\n",
      "Epoch 5/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1302 - acc: 0.9435: 0s - loss: 0.1185 \n",
      "Epoch 6/150\n",
      "23735/23735 [==============================] - ETA: 0s - loss: 0.1276 - acc: 0.944 - 1s 28us/step - loss: 0.1274 - acc: 0.9442\n",
      "Epoch 7/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1269 - acc: 0.9454\n",
      "Epoch 8/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1244 - acc: 0.9455\n",
      "Epoch 9/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1245 - acc: 0.9450\n",
      "Epoch 10/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1224 - acc: 0.9466\n",
      "Epoch 11/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.1205 - acc: 0.9465\n",
      "Epoch 12/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.1203 - acc: 0.9467\n",
      "Epoch 13/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1196 - acc: 0.9478\n",
      "Epoch 14/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1191 - acc: 0.9472\n",
      "Epoch 15/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1172 - acc: 0.9485\n",
      "Epoch 16/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1173 - acc: 0.9476\n",
      "Epoch 17/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1160 - acc: 0.9497: 0s - loss: 0.1070 - a\n",
      "Epoch 18/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1157 - acc: 0.9494\n",
      "Epoch 19/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1136 - acc: 0.9493\n",
      "Epoch 20/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.1134 - acc: 0.9499\n",
      "Epoch 21/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1141 - acc: 0.9490\n",
      "Epoch 22/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1113 - acc: 0.9499\n",
      "Epoch 23/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.1103 - acc: 0.9503\n",
      "Epoch 24/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.1098 - acc: 0.9499\n",
      "Epoch 25/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1078 - acc: 0.9531\n",
      "Epoch 26/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1090 - acc: 0.9517\n",
      "Epoch 27/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1074 - acc: 0.9516\n",
      "Epoch 28/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1058 - acc: 0.9522\n",
      "Epoch 29/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.1057 - acc: 0.9534\n",
      "Epoch 30/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1047 - acc: 0.9534\n",
      "Epoch 31/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1041 - acc: 0.9533\n",
      "Epoch 32/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1035 - acc: 0.9542\n",
      "Epoch 33/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1029 - acc: 0.9533: 0s - loss: 0.1004 - \n",
      "Epoch 34/150\n",
      "23735/23735 [==============================] - 1s 29us/step - loss: 0.1019 - acc: 0.9536\n",
      "Epoch 35/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1016 - acc: 0.9536\n",
      "Epoch 36/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.1018 - acc: 0.9536\n",
      "Epoch 37/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0999 - acc: 0.9541\n",
      "Epoch 38/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0996 - acc: 0.9550\n",
      "Epoch 39/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0988 - acc: 0.9561\n",
      "Epoch 40/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0992 - acc: 0.9549: 0s - loss: 0.0985 \n",
      "Epoch 41/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0972 - acc: 0.9555\n",
      "Epoch 42/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0972 - acc: 0.9556\n",
      "Epoch 43/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0975 - acc: 0.9561\n",
      "Epoch 44/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0958 - acc: 0.9555\n",
      "Epoch 45/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0953 - acc: 0.9554\n",
      "Epoch 46/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.0957 - acc: 0.9553\n",
      "Epoch 47/150\n",
      "23735/23735 [==============================] - ETA: 0s - loss: 0.0932 - acc: 0.956 - 1s 28us/step - loss: 0.0934 - acc: 0.9567\n",
      "Epoch 48/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0937 - acc: 0.9564\n",
      "Epoch 49/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0935 - acc: 0.9564\n",
      "Epoch 50/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0922 - acc: 0.9572\n",
      "Epoch 51/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0924 - acc: 0.9574\n",
      "Epoch 52/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.0920 - acc: 0.9579\n",
      "Epoch 53/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0914 - acc: 0.9576\n",
      "Epoch 54/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0921 - acc: 0.9587\n",
      "Epoch 55/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0908 - acc: 0.9578\n",
      "Epoch 56/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0896 - acc: 0.9586\n",
      "Epoch 57/150\n",
      "23735/23735 [==============================] - 1s 29us/step - loss: 0.0886 - acc: 0.9589\n",
      "Epoch 58/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0880 - acc: 0.9593\n",
      "Epoch 59/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0895 - acc: 0.9590\n",
      "Epoch 60/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0879 - acc: 0.9593\n",
      "Epoch 61/150\n",
      "23735/23735 [==============================] - 1s 29us/step - loss: 0.0873 - acc: 0.9595\n",
      "Epoch 62/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0877 - acc: 0.9600\n",
      "Epoch 63/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0867 - acc: 0.9595\n",
      "Epoch 64/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0852 - acc: 0.9599\n",
      "Epoch 65/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0856 - acc: 0.9601\n",
      "Epoch 66/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0844 - acc: 0.9595\n",
      "Epoch 67/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0848 - acc: 0.9606\n",
      "Epoch 68/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0828 - acc: 0.9613\n",
      "Epoch 69/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0841 - acc: 0.9612\n",
      "Epoch 70/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0837 - acc: 0.9602\n",
      "Epoch 71/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0821 - acc: 0.9612\n",
      "Epoch 72/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0813 - acc: 0.9618\n",
      "Epoch 73/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0821 - acc: 0.9611\n",
      "Epoch 74/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0814 - acc: 0.9625\n",
      "Epoch 75/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0820 - acc: 0.9631\n",
      "Epoch 76/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0808 - acc: 0.9622\n",
      "Epoch 77/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0804 - acc: 0.9619\n",
      "Epoch 78/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0800 - acc: 0.9628\n",
      "Epoch 79/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0790 - acc: 0.9626\n",
      "Epoch 80/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0780 - acc: 0.9633\n",
      "Epoch 81/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0805 - acc: 0.9624\n",
      "Epoch 82/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0789 - acc: 0.9633\n",
      "Epoch 83/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0791 - acc: 0.9634\n",
      "Epoch 84/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0792 - acc: 0.9633\n",
      "Epoch 85/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0786 - acc: 0.9632\n",
      "Epoch 86/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0770 - acc: 0.9641\n",
      "Epoch 87/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0790 - acc: 0.9625\n",
      "Epoch 88/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0788 - acc: 0.9631\n",
      "Epoch 89/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0751 - acc: 0.9634\n",
      "Epoch 90/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0766 - acc: 0.9626\n",
      "Epoch 91/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0771 - acc: 0.9641\n",
      "Epoch 92/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0771 - acc: 0.9629\n",
      "Epoch 93/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0746 - acc: 0.9644\n",
      "Epoch 94/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0745 - acc: 0.9639: 0s - loss: 0.0709 - \n",
      "Epoch 95/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0762 - acc: 0.9647\n",
      "Epoch 96/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0763 - acc: 0.9644\n",
      "Epoch 97/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0743 - acc: 0.9654\n",
      "Epoch 98/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0755 - acc: 0.9646\n",
      "Epoch 99/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0723 - acc: 0.9654\n",
      "Epoch 100/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0730 - acc: 0.9653\n",
      "Epoch 101/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0715 - acc: 0.9655\n",
      "Epoch 102/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0754 - acc: 0.9642\n",
      "Epoch 103/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0732 - acc: 0.9654\n",
      "Epoch 104/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.0734 - acc: 0.9642\n",
      "Epoch 105/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0731 - acc: 0.9654\n",
      "Epoch 106/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0732 - acc: 0.9654\n",
      "Epoch 107/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0723 - acc: 0.9652\n",
      "Epoch 108/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.0729 - acc: 0.9663\n",
      "Epoch 109/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0705 - acc: 0.9666\n",
      "Epoch 110/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.0712 - acc: 0.9652\n",
      "Epoch 111/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0716 - acc: 0.9668\n",
      "Epoch 112/150\n",
      "23735/23735 [==============================] - 1s 27us/step - loss: 0.0735 - acc: 0.9654\n",
      "Epoch 113/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0722 - acc: 0.9667\n",
      "Epoch 114/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0703 - acc: 0.9663\n",
      "Epoch 115/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0717 - acc: 0.9668\n",
      "Epoch 116/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0694 - acc: 0.9675\n",
      "Epoch 117/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0686 - acc: 0.9676\n",
      "Epoch 118/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0692 - acc: 0.9674\n",
      "Epoch 119/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0688 - acc: 0.9679\n",
      "Epoch 120/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0697 - acc: 0.9669\n",
      "Epoch 121/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0684 - acc: 0.9679\n",
      "Epoch 122/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0680 - acc: 0.9689\n",
      "Epoch 123/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0688 - acc: 0.9674\n",
      "Epoch 124/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0693 - acc: 0.9681\n",
      "Epoch 125/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0692 - acc: 0.9688: 0s - loss: 0.0692 - \n",
      "Epoch 126/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0675 - acc: 0.9687\n",
      "Epoch 127/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0682 - acc: 0.9695\n",
      "Epoch 128/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0681 - acc: 0.9687\n",
      "Epoch 129/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0653 - acc: 0.9698\n",
      "Epoch 130/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0675 - acc: 0.9693\n",
      "Epoch 131/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0657 - acc: 0.9693\n",
      "Epoch 132/150\n",
      "23735/23735 [==============================] - ETA: 0s - loss: 0.0659 - acc: 0.970 - 1s 28us/step - loss: 0.0660 - acc: 0.9699\n",
      "Epoch 133/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0663 - acc: 0.9698\n",
      "Epoch 134/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0668 - acc: 0.9693: 0s - loss: 0.0619 - \n",
      "Epoch 135/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0649 - acc: 0.9703\n",
      "Epoch 136/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0656 - acc: 0.9705\n",
      "Epoch 137/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0655 - acc: 0.9702\n",
      "Epoch 138/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0657 - acc: 0.9700\n",
      "Epoch 139/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0664 - acc: 0.9695\n",
      "Epoch 140/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0649 - acc: 0.9703\n",
      "Epoch 141/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0653 - acc: 0.9701\n",
      "Epoch 142/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0656 - acc: 0.9700\n",
      "Epoch 143/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0649 - acc: 0.9708\n",
      "Epoch 144/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0648 - acc: 0.9703\n",
      "Epoch 145/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0646 - acc: 0.9703\n",
      "Epoch 146/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0646 - acc: 0.9702\n",
      "Epoch 147/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0656 - acc: 0.9709\n",
      "Epoch 148/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0635 - acc: 0.9707\n",
      "Epoch 149/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0645 - acc: 0.9712\n",
      "Epoch 150/150\n",
      "23735/23735 [==============================] - 1s 28us/step - loss: 0.0635 - acc: 0.9719\n",
      "Epoch 1/150\n",
      "25317/25317 [==============================] - 1s 46us/step - loss: 0.2810 - acc: 0.9180\n",
      "Epoch 2/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.2449 - acc: 0.9334\n",
      "Epoch 3/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.2450 - acc: 0.9334\n",
      "Epoch 4/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.2450 - acc: 0.9334\n",
      "Epoch 5/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.2449 - acc: 0.9334\n",
      "Epoch 6/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.2451 - acc: 0.9334\n",
      "Epoch 7/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.2288 - acc: 0.9334\n",
      "Epoch 8/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1572 - acc: 0.9349\n",
      "Epoch 9/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1410 - acc: 0.9393\n",
      "Epoch 10/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1370 - acc: 0.9407\n",
      "Epoch 11/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1347 - acc: 0.9410\n",
      "Epoch 12/150\n",
      "25317/25317 [==============================] - 1s 27us/step - loss: 0.1319 - acc: 0.9413\n",
      "Epoch 13/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1305 - acc: 0.9426\n",
      "Epoch 14/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1279 - acc: 0.9437\n",
      "Epoch 15/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1279 - acc: 0.9429\n",
      "Epoch 16/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1253 - acc: 0.9443\n",
      "Epoch 17/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1243 - acc: 0.9443\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25317/25317 [==============================] - 1s 27us/step - loss: 0.1237 - acc: 0.9454\n",
      "Epoch 19/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1218 - acc: 0.9453\n",
      "Epoch 20/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1213 - acc: 0.9459\n",
      "Epoch 21/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1199 - acc: 0.9465\n",
      "Epoch 22/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1193 - acc: 0.9473\n",
      "Epoch 23/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1185 - acc: 0.9476\n",
      "Epoch 24/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1185 - acc: 0.9477\n",
      "Epoch 25/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1168 - acc: 0.9479\n",
      "Epoch 26/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1158 - acc: 0.9492\n",
      "Epoch 27/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1138 - acc: 0.9490\n",
      "Epoch 28/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1140 - acc: 0.9490\n",
      "Epoch 29/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1126 - acc: 0.9503\n",
      "Epoch 30/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1131 - acc: 0.9504\n",
      "Epoch 31/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1118 - acc: 0.9497\n",
      "Epoch 32/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1106 - acc: 0.9511\n",
      "Epoch 33/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1100 - acc: 0.9517\n",
      "Epoch 34/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1097 - acc: 0.9509\n",
      "Epoch 35/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1092 - acc: 0.9523\n",
      "Epoch 36/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1086 - acc: 0.9514\n",
      "Epoch 37/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1081 - acc: 0.9517\n",
      "Epoch 38/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1062 - acc: 0.9530\n",
      "Epoch 39/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1065 - acc: 0.9529\n",
      "Epoch 40/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1057 - acc: 0.9539\n",
      "Epoch 41/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1050 - acc: 0.9534\n",
      "Epoch 42/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1041 - acc: 0.9545\n",
      "Epoch 43/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1037 - acc: 0.9540\n",
      "Epoch 44/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1025 - acc: 0.9551\n",
      "Epoch 45/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1035 - acc: 0.9546\n",
      "Epoch 46/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1021 - acc: 0.9554\n",
      "Epoch 47/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1012 - acc: 0.9559\n",
      "Epoch 48/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1016 - acc: 0.9557\n",
      "Epoch 49/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1001 - acc: 0.9564\n",
      "Epoch 50/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1001 - acc: 0.9556\n",
      "Epoch 51/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1003 - acc: 0.9562\n",
      "Epoch 52/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.1000 - acc: 0.9567\n",
      "Epoch 53/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0983 - acc: 0.9569\n",
      "Epoch 54/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0986 - acc: 0.9565\n",
      "Epoch 55/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0977 - acc: 0.9577\n",
      "Epoch 56/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0974 - acc: 0.9577\n",
      "Epoch 57/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0969 - acc: 0.9580\n",
      "Epoch 58/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0961 - acc: 0.9578\n",
      "Epoch 59/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0953 - acc: 0.9581\n",
      "Epoch 60/150\n",
      "25317/25317 [==============================] - 1s 29us/step - loss: 0.0963 - acc: 0.9582\n",
      "Epoch 61/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0967 - acc: 0.9579\n",
      "Epoch 62/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0955 - acc: 0.9586\n",
      "Epoch 63/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0948 - acc: 0.9590\n",
      "Epoch 64/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0950 - acc: 0.9582\n",
      "Epoch 65/150\n",
      "25317/25317 [==============================] - 1s 27us/step - loss: 0.0943 - acc: 0.9596\n",
      "Epoch 66/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0930 - acc: 0.9598\n",
      "Epoch 67/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0932 - acc: 0.9592\n",
      "Epoch 68/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0932 - acc: 0.9596\n",
      "Epoch 69/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0926 - acc: 0.9596\n",
      "Epoch 70/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0932 - acc: 0.9588\n",
      "Epoch 71/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0915 - acc: 0.9602\n",
      "Epoch 72/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0925 - acc: 0.9599\n",
      "Epoch 73/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0915 - acc: 0.9604\n",
      "Epoch 74/150\n",
      "25317/25317 [==============================] - 1s 29us/step - loss: 0.0905 - acc: 0.9605\n",
      "Epoch 75/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0908 - acc: 0.9601\n",
      "Epoch 76/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0908 - acc: 0.9610\n",
      "Epoch 77/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0921 - acc: 0.9603\n",
      "Epoch 78/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0899 - acc: 0.9604\n",
      "Epoch 79/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0893 - acc: 0.9620\n",
      "Epoch 80/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0901 - acc: 0.9609\n",
      "Epoch 81/150\n",
      "25317/25317 [==============================] - 1s 27us/step - loss: 0.0901 - acc: 0.9604\n",
      "Epoch 82/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0895 - acc: 0.9612\n",
      "Epoch 83/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0878 - acc: 0.9620\n",
      "Epoch 84/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0892 - acc: 0.9603\n",
      "Epoch 85/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0879 - acc: 0.9613\n",
      "Epoch 86/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0874 - acc: 0.9624\n",
      "Epoch 87/150\n",
      "25317/25317 [==============================] - ETA: 0s - loss: 0.0868 - acc: 0.962 - 1s 28us/step - loss: 0.0872 - acc: 0.9621\n",
      "Epoch 88/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0890 - acc: 0.9602\n",
      "Epoch 89/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0886 - acc: 0.9620\n",
      "Epoch 90/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0878 - acc: 0.9619\n",
      "Epoch 91/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0869 - acc: 0.9626\n",
      "Epoch 92/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0864 - acc: 0.9620\n",
      "Epoch 93/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0866 - acc: 0.9624\n",
      "Epoch 94/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0851 - acc: 0.9628\n",
      "Epoch 95/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0853 - acc: 0.9634\n",
      "Epoch 96/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0881 - acc: 0.9613\n",
      "Epoch 97/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0850 - acc: 0.9629\n",
      "Epoch 98/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0852 - acc: 0.9633\n",
      "Epoch 99/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0850 - acc: 0.9638\n",
      "Epoch 100/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0851 - acc: 0.9627\n",
      "Epoch 101/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0867 - acc: 0.9629\n",
      "Epoch 102/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0852 - acc: 0.9636\n",
      "Epoch 103/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0834 - acc: 0.9626\n",
      "Epoch 104/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0848 - acc: 0.9630\n",
      "Epoch 105/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0844 - acc: 0.9628\n",
      "Epoch 106/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0838 - acc: 0.9645\n",
      "Epoch 107/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0832 - acc: 0.9641\n",
      "Epoch 108/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0836 - acc: 0.9642\n",
      "Epoch 109/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0845 - acc: 0.9629\n",
      "Epoch 110/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0845 - acc: 0.9635\n",
      "Epoch 111/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0825 - acc: 0.9638\n",
      "Epoch 112/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0841 - acc: 0.9633\n",
      "Epoch 113/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0825 - acc: 0.9644\n",
      "Epoch 114/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0827 - acc: 0.9641\n",
      "Epoch 115/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0826 - acc: 0.9638\n",
      "Epoch 116/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0824 - acc: 0.9646\n",
      "Epoch 117/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0818 - acc: 0.9652\n",
      "Epoch 118/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0814 - acc: 0.9652\n",
      "Epoch 119/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0822 - acc: 0.9645\n",
      "Epoch 120/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0836 - acc: 0.9640\n",
      "Epoch 121/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0807 - acc: 0.9650\n",
      "Epoch 122/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0818 - acc: 0.9645\n",
      "Epoch 123/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0817 - acc: 0.9650\n",
      "Epoch 124/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0806 - acc: 0.9655\n",
      "Epoch 125/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0796 - acc: 0.9654\n",
      "Epoch 126/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0820 - acc: 0.9640\n",
      "Epoch 127/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0809 - acc: 0.9653\n",
      "Epoch 128/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0833 - acc: 0.9643\n",
      "Epoch 129/150\n",
      "25317/25317 [==============================] - 1s 27us/step - loss: 0.0793 - acc: 0.9660\n",
      "Epoch 130/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0798 - acc: 0.9652\n",
      "Epoch 131/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0791 - acc: 0.9661\n",
      "Epoch 132/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0813 - acc: 0.9650\n",
      "Epoch 133/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0783 - acc: 0.9665\n",
      "Epoch 134/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0797 - acc: 0.9657\n",
      "Epoch 135/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0797 - acc: 0.9658\n",
      "Epoch 136/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0794 - acc: 0.9656\n",
      "Epoch 137/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0791 - acc: 0.9660\n",
      "Epoch 138/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0792 - acc: 0.9657\n",
      "Epoch 139/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0792 - acc: 0.9659\n",
      "Epoch 140/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0788 - acc: 0.9660\n",
      "Epoch 141/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0785 - acc: 0.9669\n",
      "Epoch 142/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0801 - acc: 0.9654\n",
      "Epoch 143/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0782 - acc: 0.9668\n",
      "Epoch 144/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0802 - acc: 0.9660\n",
      "Epoch 145/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0776 - acc: 0.9670\n",
      "Epoch 146/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0784 - acc: 0.9660\n",
      "Epoch 147/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0790 - acc: 0.9659\n",
      "Epoch 148/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0795 - acc: 0.9661\n",
      "Epoch 149/150\n",
      "25317/25317 [==============================] - 1s 28us/step - loss: 0.0768 - acc: 0.9670\n",
      "Epoch 150/150\n",
      "25317/25317 [==============================] - 1s 29us/step - loss: 0.0792 - acc: 0.9654\n",
      "Epoch 1/150\n",
      "26900/26900 [==============================] - 1s 42us/step - loss: 0.2519 - acc: 0.9323\n",
      "Epoch 2/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1797 - acc: 0.9328\n",
      "Epoch 3/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1460 - acc: 0.9378\n",
      "Epoch 4/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1409 - acc: 0.9390\n",
      "Epoch 5/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1377 - acc: 0.9398\n",
      "Epoch 6/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1345 - acc: 0.9407\n",
      "Epoch 7/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1337 - acc: 0.9410\n",
      "Epoch 8/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1322 - acc: 0.9407\n",
      "Epoch 9/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1290 - acc: 0.9420\n",
      "Epoch 10/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1293 - acc: 0.9430\n",
      "Epoch 11/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1274 - acc: 0.9430\n",
      "Epoch 12/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1270 - acc: 0.9439\n",
      "Epoch 13/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1262 - acc: 0.9438\n",
      "Epoch 14/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1238 - acc: 0.9445\n",
      "Epoch 15/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1243 - acc: 0.9454\n",
      "Epoch 16/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1229 - acc: 0.9456\n",
      "Epoch 17/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1217 - acc: 0.9457\n",
      "Epoch 18/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1218 - acc: 0.9460\n",
      "Epoch 19/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1203 - acc: 0.9462\n",
      "Epoch 20/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1191 - acc: 0.9471\n",
      "Epoch 21/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1181 - acc: 0.9473\n",
      "Epoch 22/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1169 - acc: 0.9473\n",
      "Epoch 23/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1188 - acc: 0.9477\n",
      "Epoch 24/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1163 - acc: 0.9483\n",
      "Epoch 25/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1153 - acc: 0.9484\n",
      "Epoch 26/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1154 - acc: 0.9482\n",
      "Epoch 27/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1147 - acc: 0.9493\n",
      "Epoch 28/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1128 - acc: 0.9494\n",
      "Epoch 29/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1132 - acc: 0.9501\n",
      "Epoch 30/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1121 - acc: 0.9501: 0s - loss: 0.1077 \n",
      "Epoch 31/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1107 - acc: 0.9503\n",
      "Epoch 32/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1101 - acc: 0.9509\n",
      "Epoch 33/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1090 - acc: 0.9508\n",
      "Epoch 34/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1083 - acc: 0.9514\n",
      "Epoch 35/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1077 - acc: 0.9510\n",
      "Epoch 36/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1070 - acc: 0.9522\n",
      "Epoch 37/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1061 - acc: 0.9520\n",
      "Epoch 38/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1057 - acc: 0.9516\n",
      "Epoch 39/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1055 - acc: 0.9516\n",
      "Epoch 40/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1037 - acc: 0.9530\n",
      "Epoch 41/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1038 - acc: 0.9538\n",
      "Epoch 42/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1025 - acc: 0.9539\n",
      "Epoch 43/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1014 - acc: 0.9543\n",
      "Epoch 44/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1021 - acc: 0.9541\n",
      "Epoch 45/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.1011 - acc: 0.9549\n",
      "Epoch 46/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.1000 - acc: 0.9559\n",
      "Epoch 47/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0990 - acc: 0.9554\n",
      "Epoch 48/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0987 - acc: 0.9552\n",
      "Epoch 49/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0985 - acc: 0.9558\n",
      "Epoch 50/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0985 - acc: 0.9561\n",
      "Epoch 51/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0969 - acc: 0.9560\n",
      "Epoch 52/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0963 - acc: 0.9568\n",
      "Epoch 53/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0952 - acc: 0.9569\n",
      "Epoch 54/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0949 - acc: 0.9577\n",
      "Epoch 55/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0951 - acc: 0.9574\n",
      "Epoch 56/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0930 - acc: 0.9579\n",
      "Epoch 57/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0938 - acc: 0.9569\n",
      "Epoch 58/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0927 - acc: 0.9591\n",
      "Epoch 59/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0925 - acc: 0.9591\n",
      "Epoch 60/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0921 - acc: 0.9591\n",
      "Epoch 61/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0912 - acc: 0.9584\n",
      "Epoch 62/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0880 - acc: 0.9602\n",
      "Epoch 63/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0902 - acc: 0.9594\n",
      "Epoch 64/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0898 - acc: 0.9605\n",
      "Epoch 65/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0883 - acc: 0.9599\n",
      "Epoch 66/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0893 - acc: 0.9604\n",
      "Epoch 67/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0870 - acc: 0.9612\n",
      "Epoch 68/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0879 - acc: 0.9607\n",
      "Epoch 69/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0895 - acc: 0.9605\n",
      "Epoch 70/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0869 - acc: 0.9604\n",
      "Epoch 71/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0862 - acc: 0.9612\n",
      "Epoch 72/150\n",
      "26900/26900 [==============================] - 1s 30us/step - loss: 0.0847 - acc: 0.9616\n",
      "Epoch 73/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0868 - acc: 0.9617\n",
      "Epoch 74/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0847 - acc: 0.9625\n",
      "Epoch 75/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0849 - acc: 0.9614\n",
      "Epoch 76/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0835 - acc: 0.9631\n",
      "Epoch 77/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0819 - acc: 0.9636\n",
      "Epoch 78/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0843 - acc: 0.9620\n",
      "Epoch 79/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0824 - acc: 0.9631\n",
      "Epoch 80/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0813 - acc: 0.9639\n",
      "Epoch 81/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0840 - acc: 0.9625\n",
      "Epoch 82/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0839 - acc: 0.9629\n",
      "Epoch 83/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0815 - acc: 0.9633\n",
      "Epoch 84/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0832 - acc: 0.9636\n",
      "Epoch 85/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0800 - acc: 0.9635\n",
      "Epoch 86/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0790 - acc: 0.9640\n",
      "Epoch 87/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0786 - acc: 0.9651\n",
      "Epoch 88/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0808 - acc: 0.9631\n",
      "Epoch 89/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0805 - acc: 0.9638\n",
      "Epoch 90/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0796 - acc: 0.9650\n",
      "Epoch 91/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0783 - acc: 0.9648\n",
      "Epoch 92/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0786 - acc: 0.9661\n",
      "Epoch 93/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0773 - acc: 0.9658\n",
      "Epoch 94/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0784 - acc: 0.9649\n",
      "Epoch 95/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0771 - acc: 0.9662\n",
      "Epoch 96/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0781 - acc: 0.9658\n",
      "Epoch 97/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0776 - acc: 0.9654\n",
      "Epoch 98/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0752 - acc: 0.9659\n",
      "Epoch 99/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0757 - acc: 0.9671\n",
      "Epoch 100/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0789 - acc: 0.9659\n",
      "Epoch 101/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0762 - acc: 0.9657\n",
      "Epoch 102/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0764 - acc: 0.9658\n",
      "Epoch 103/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0748 - acc: 0.9672\n",
      "Epoch 104/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0746 - acc: 0.9658\n",
      "Epoch 105/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0762 - acc: 0.9663\n",
      "Epoch 106/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0756 - acc: 0.9658\n",
      "Epoch 107/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0752 - acc: 0.9659\n",
      "Epoch 108/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0752 - acc: 0.9660\n",
      "Epoch 109/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0757 - acc: 0.9667\n",
      "Epoch 110/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0728 - acc: 0.9669\n",
      "Epoch 111/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0742 - acc: 0.9668\n",
      "Epoch 112/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0738 - acc: 0.9675\n",
      "Epoch 113/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0750 - acc: 0.9666\n",
      "Epoch 114/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0732 - acc: 0.9672\n",
      "Epoch 115/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0730 - acc: 0.9684\n",
      "Epoch 116/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0715 - acc: 0.9678\n",
      "Epoch 117/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0731 - acc: 0.9678\n",
      "Epoch 118/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0740 - acc: 0.9678\n",
      "Epoch 119/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0715 - acc: 0.9681\n",
      "Epoch 120/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0715 - acc: 0.9677\n",
      "Epoch 121/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0708 - acc: 0.9682\n",
      "Epoch 122/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0754 - acc: 0.9673\n",
      "Epoch 123/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0730 - acc: 0.9675\n",
      "Epoch 124/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0743 - acc: 0.9671\n",
      "Epoch 125/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0729 - acc: 0.9679\n",
      "Epoch 126/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0736 - acc: 0.9673\n",
      "Epoch 127/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0702 - acc: 0.9695\n",
      "Epoch 128/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0716 - acc: 0.9678\n",
      "Epoch 129/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0719 - acc: 0.9684\n",
      "Epoch 130/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0702 - acc: 0.9688\n",
      "Epoch 131/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0722 - acc: 0.9678\n",
      "Epoch 132/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0692 - acc: 0.9696\n",
      "Epoch 133/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0702 - acc: 0.9681\n",
      "Epoch 134/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0709 - acc: 0.9683\n",
      "Epoch 135/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0703 - acc: 0.9694\n",
      "Epoch 136/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0692 - acc: 0.9690\n",
      "Epoch 137/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0714 - acc: 0.9679\n",
      "Epoch 138/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0707 - acc: 0.9687\n",
      "Epoch 139/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0704 - acc: 0.9689\n",
      "Epoch 140/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0682 - acc: 0.9696\n",
      "Epoch 141/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0690 - acc: 0.9695\n",
      "Epoch 142/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0700 - acc: 0.9687\n",
      "Epoch 143/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0698 - acc: 0.9676\n",
      "Epoch 144/150\n",
      "26900/26900 [==============================] - 1s 29us/step - loss: 0.0710 - acc: 0.9691\n",
      "Epoch 145/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0693 - acc: 0.9696\n",
      "Epoch 146/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0679 - acc: 0.9699\n",
      "Epoch 147/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0672 - acc: 0.9697\n",
      "Epoch 148/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0689 - acc: 0.9696\n",
      "Epoch 149/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0676 - acc: 0.9706\n",
      "Epoch 150/150\n",
      "26900/26900 [==============================] - 1s 28us/step - loss: 0.0686 - acc: 0.9695\n",
      "Epoch 1/150\n",
      "28482/28482 [==============================] - 1s 42us/step - loss: 0.3203 - acc: 0.8968\n",
      "Epoch 2/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.2745 - acc: 0.9218\n",
      "Epoch 3/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.2745 - acc: 0.9218\n",
      "Epoch 4/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.2746 - acc: 0.9218\n",
      "Epoch 5/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.2744 - acc: 0.9218\n",
      "Epoch 6/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.2745 - acc: 0.9218\n",
      "Epoch 7/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.2623 - acc: 0.9218\n",
      "Epoch 8/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1829 - acc: 0.9275\n",
      "Epoch 9/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1612 - acc: 0.9283\n",
      "Epoch 10/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1556 - acc: 0.9309\n",
      "Epoch 11/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1509 - acc: 0.9314\n",
      "Epoch 12/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1477 - acc: 0.9319\n",
      "Epoch 13/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1462 - acc: 0.9327\n",
      "Epoch 14/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1435 - acc: 0.9347\n",
      "Epoch 15/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1420 - acc: 0.9345\n",
      "Epoch 16/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1405 - acc: 0.9359\n",
      "Epoch 17/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1387 - acc: 0.9368\n",
      "Epoch 18/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1392 - acc: 0.9367\n",
      "Epoch 19/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1374 - acc: 0.9379\n",
      "Epoch 20/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1358 - acc: 0.9385\n",
      "Epoch 21/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1341 - acc: 0.9383\n",
      "Epoch 22/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1336 - acc: 0.9390\n",
      "Epoch 23/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1323 - acc: 0.9399\n",
      "Epoch 24/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1312 - acc: 0.9403\n",
      "Epoch 25/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1311 - acc: 0.9413\n",
      "Epoch 26/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1294 - acc: 0.9418\n",
      "Epoch 27/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1290 - acc: 0.9422\n",
      "Epoch 28/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1271 - acc: 0.9432\n",
      "Epoch 29/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1280 - acc: 0.9418\n",
      "Epoch 30/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1266 - acc: 0.9428\n",
      "Epoch 31/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1265 - acc: 0.9430\n",
      "Epoch 32/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1245 - acc: 0.9445\n",
      "Epoch 33/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1237 - acc: 0.9447\n",
      "Epoch 34/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1254 - acc: 0.9448\n",
      "Epoch 35/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1254 - acc: 0.9439\n",
      "Epoch 36/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1221 - acc: 0.9458\n",
      "Epoch 37/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1220 - acc: 0.9465\n",
      "Epoch 38/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1205 - acc: 0.9463\n",
      "Epoch 39/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1208 - acc: 0.9455\n",
      "Epoch 40/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1200 - acc: 0.9478\n",
      "Epoch 41/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1190 - acc: 0.9478\n",
      "Epoch 42/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1190 - acc: 0.9475\n",
      "Epoch 43/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1181 - acc: 0.9471\n",
      "Epoch 44/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1175 - acc: 0.9472\n",
      "Epoch 45/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1180 - acc: 0.9479\n",
      "Epoch 46/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1170 - acc: 0.9480\n",
      "Epoch 47/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1164 - acc: 0.9473\n",
      "Epoch 48/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1157 - acc: 0.9490\n",
      "Epoch 49/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1157 - acc: 0.9483\n",
      "Epoch 50/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1141 - acc: 0.9488\n",
      "Epoch 51/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1145 - acc: 0.9487\n",
      "Epoch 52/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1134 - acc: 0.9487\n",
      "Epoch 53/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1136 - acc: 0.9496\n",
      "Epoch 54/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1133 - acc: 0.9496\n",
      "Epoch 55/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1125 - acc: 0.9498\n",
      "Epoch 56/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1117 - acc: 0.9495\n",
      "Epoch 57/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1116 - acc: 0.9498\n",
      "Epoch 58/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1117 - acc: 0.9510\n",
      "Epoch 59/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1102 - acc: 0.9505\n",
      "Epoch 60/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1106 - acc: 0.9505\n",
      "Epoch 61/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1101 - acc: 0.9511\n",
      "Epoch 62/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1108 - acc: 0.9494\n",
      "Epoch 63/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1098 - acc: 0.9498\n",
      "Epoch 64/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1090 - acc: 0.9517\n",
      "Epoch 65/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1098 - acc: 0.9505\n",
      "Epoch 66/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1093 - acc: 0.9505\n",
      "Epoch 67/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1082 - acc: 0.9515\n",
      "Epoch 68/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1081 - acc: 0.9515\n",
      "Epoch 69/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1112 - acc: 0.9508\n",
      "Epoch 70/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1056 - acc: 0.9528\n",
      "Epoch 71/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1065 - acc: 0.9523\n",
      "Epoch 72/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1068 - acc: 0.9525\n",
      "Epoch 73/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1058 - acc: 0.9526\n",
      "Epoch 74/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1058 - acc: 0.9531\n",
      "Epoch 75/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1065 - acc: 0.9529\n",
      "Epoch 76/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1055 - acc: 0.9527\n",
      "Epoch 77/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1050 - acc: 0.9529\n",
      "Epoch 78/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1044 - acc: 0.9527\n",
      "Epoch 79/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1037 - acc: 0.9537\n",
      "Epoch 80/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1032 - acc: 0.9534\n",
      "Epoch 81/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1054 - acc: 0.9536\n",
      "Epoch 82/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1060 - acc: 0.9526\n",
      "Epoch 83/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1036 - acc: 0.9543\n",
      "Epoch 84/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1031 - acc: 0.9528\n",
      "Epoch 85/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1027 - acc: 0.9541\n",
      "Epoch 86/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1021 - acc: 0.9540\n",
      "Epoch 87/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1017 - acc: 0.9548\n",
      "Epoch 88/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1009 - acc: 0.9548\n",
      "Epoch 89/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1023 - acc: 0.9540\n",
      "Epoch 90/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1013 - acc: 0.9544\n",
      "Epoch 91/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1002 - acc: 0.9550\n",
      "Epoch 92/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.1001 - acc: 0.9552\n",
      "Epoch 93/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0998 - acc: 0.9550\n",
      "Epoch 94/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1008 - acc: 0.9551\n",
      "Epoch 95/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.1006 - acc: 0.9541\n",
      "Epoch 96/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0986 - acc: 0.9555\n",
      "Epoch 97/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0996 - acc: 0.9559\n",
      "Epoch 98/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0973 - acc: 0.9555\n",
      "Epoch 99/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0980 - acc: 0.9558\n",
      "Epoch 100/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0990 - acc: 0.9555\n",
      "Epoch 101/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0980 - acc: 0.9564\n",
      "Epoch 102/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0979 - acc: 0.9563\n",
      "Epoch 103/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0963 - acc: 0.9558\n",
      "Epoch 104/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0956 - acc: 0.9566\n",
      "Epoch 105/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0968 - acc: 0.9567\n",
      "Epoch 106/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0963 - acc: 0.9563\n",
      "Epoch 107/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0951 - acc: 0.9574\n",
      "Epoch 108/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0970 - acc: 0.9561\n",
      "Epoch 109/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0949 - acc: 0.9571\n",
      "Epoch 110/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0947 - acc: 0.9560\n",
      "Epoch 111/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0954 - acc: 0.9565\n",
      "Epoch 112/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0942 - acc: 0.9573\n",
      "Epoch 113/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0985 - acc: 0.9545\n",
      "Epoch 114/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0948 - acc: 0.9571\n",
      "Epoch 115/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0936 - acc: 0.9584\n",
      "Epoch 116/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0929 - acc: 0.9576\n",
      "Epoch 117/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0929 - acc: 0.9575\n",
      "Epoch 118/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0917 - acc: 0.9584\n",
      "Epoch 119/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0912 - acc: 0.9578\n",
      "Epoch 120/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0948 - acc: 0.9574\n",
      "Epoch 121/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0922 - acc: 0.9574\n",
      "Epoch 122/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0933 - acc: 0.9579\n",
      "Epoch 123/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0925 - acc: 0.9573\n",
      "Epoch 124/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0901 - acc: 0.9591\n",
      "Epoch 125/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0918 - acc: 0.9580\n",
      "Epoch 126/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0905 - acc: 0.9583\n",
      "Epoch 127/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0915 - acc: 0.9574\n",
      "Epoch 128/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0899 - acc: 0.9584\n",
      "Epoch 129/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0893 - acc: 0.9586\n",
      "Epoch 130/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0893 - acc: 0.9587\n",
      "Epoch 131/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0953 - acc: 0.9573\n",
      "Epoch 132/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0904 - acc: 0.9590\n",
      "Epoch 133/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0894 - acc: 0.9589\n",
      "Epoch 134/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0879 - acc: 0.9590\n",
      "Epoch 135/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0911 - acc: 0.9589\n",
      "Epoch 136/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0891 - acc: 0.9582\n",
      "Epoch 137/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0882 - acc: 0.9587\n",
      "Epoch 138/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0881 - acc: 0.9600\n",
      "Epoch 139/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0884 - acc: 0.9592\n",
      "Epoch 140/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0869 - acc: 0.9602\n",
      "Epoch 141/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0894 - acc: 0.9589\n",
      "Epoch 142/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0883 - acc: 0.9587\n",
      "Epoch 143/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0868 - acc: 0.9593\n",
      "Epoch 144/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0874 - acc: 0.9599\n",
      "Epoch 145/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0885 - acc: 0.9594\n",
      "Epoch 146/150\n",
      "28482/28482 [==============================] - 1s 29us/step - loss: 0.0858 - acc: 0.9594\n",
      "Epoch 147/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0842 - acc: 0.9601\n",
      "Epoch 148/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0878 - acc: 0.9597\n",
      "Epoch 149/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0872 - acc: 0.9605\n",
      "Epoch 150/150\n",
      "28482/28482 [==============================] - 1s 28us/step - loss: 0.0890 - acc: 0.9592\n",
      "Epoch 1/150\n",
      "30065/30065 [==============================] - 1s 43us/step - loss: 0.3380 - acc: 0.8892\n",
      "Epoch 2/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.3147 - acc: 0.9047\n",
      "Epoch 3/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.3146 - acc: 0.9047: 0s - loss: 0.3\n",
      "Epoch 4/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.2611 - acc: 0.9046\n",
      "Epoch 5/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1945 - acc: 0.9086\n",
      "Epoch 6/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1828 - acc: 0.9132\n",
      "Epoch 7/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1771 - acc: 0.9147\n",
      "Epoch 8/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1740 - acc: 0.9187\n",
      "Epoch 9/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1706 - acc: 0.9194\n",
      "Epoch 10/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1688 - acc: 0.9200\n",
      "Epoch 11/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1668 - acc: 0.9224\n",
      "Epoch 12/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1654 - acc: 0.9221\n",
      "Epoch 13/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1648 - acc: 0.9232\n",
      "Epoch 14/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1618 - acc: 0.9249\n",
      "Epoch 15/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1622 - acc: 0.9251\n",
      "Epoch 16/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1607 - acc: 0.9261\n",
      "Epoch 17/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1598 - acc: 0.9255\n",
      "Epoch 18/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1580 - acc: 0.9270\n",
      "Epoch 19/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1574 - acc: 0.9273\n",
      "Epoch 20/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1557 - acc: 0.9282\n",
      "Epoch 21/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1553 - acc: 0.9284\n",
      "Epoch 22/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1544 - acc: 0.9284\n",
      "Epoch 23/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1535 - acc: 0.9295\n",
      "Epoch 24/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1519 - acc: 0.9307\n",
      "Epoch 25/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1510 - acc: 0.9314\n",
      "Epoch 26/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1499 - acc: 0.9320\n",
      "Epoch 27/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1481 - acc: 0.9334\n",
      "Epoch 28/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1473 - acc: 0.9333\n",
      "Epoch 29/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1462 - acc: 0.9333\n",
      "Epoch 30/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1458 - acc: 0.9340\n",
      "Epoch 31/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1453 - acc: 0.9337\n",
      "Epoch 32/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1441 - acc: 0.9341\n",
      "Epoch 33/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1438 - acc: 0.9352\n",
      "Epoch 34/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1423 - acc: 0.9360\n",
      "Epoch 35/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1411 - acc: 0.9372\n",
      "Epoch 36/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1416 - acc: 0.9353\n",
      "Epoch 37/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1396 - acc: 0.9361\n",
      "Epoch 38/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1403 - acc: 0.9360\n",
      "Epoch 39/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1383 - acc: 0.9377\n",
      "Epoch 40/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1388 - acc: 0.9384\n",
      "Epoch 41/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1373 - acc: 0.9376\n",
      "Epoch 42/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1373 - acc: 0.9391\n",
      "Epoch 43/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1363 - acc: 0.9395\n",
      "Epoch 44/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1364 - acc: 0.9397\n",
      "Epoch 45/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1342 - acc: 0.9397\n",
      "Epoch 46/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1344 - acc: 0.9399\n",
      "Epoch 47/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1333 - acc: 0.9420\n",
      "Epoch 48/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1328 - acc: 0.9417\n",
      "Epoch 49/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1319 - acc: 0.9425\n",
      "Epoch 50/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1304 - acc: 0.9420\n",
      "Epoch 51/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1314 - acc: 0.9409\n",
      "Epoch 52/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1296 - acc: 0.9431\n",
      "Epoch 53/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1286 - acc: 0.9429\n",
      "Epoch 54/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1288 - acc: 0.9435\n",
      "Epoch 55/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1289 - acc: 0.9430\n",
      "Epoch 56/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1275 - acc: 0.9432\n",
      "Epoch 57/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1267 - acc: 0.9438\n",
      "Epoch 58/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1261 - acc: 0.9449\n",
      "Epoch 59/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1261 - acc: 0.9440\n",
      "Epoch 60/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1251 - acc: 0.9450\n",
      "Epoch 61/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1244 - acc: 0.9455\n",
      "Epoch 62/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1238 - acc: 0.9458\n",
      "Epoch 63/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1238 - acc: 0.9456\n",
      "Epoch 64/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1229 - acc: 0.9456\n",
      "Epoch 65/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1224 - acc: 0.9465\n",
      "Epoch 66/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1219 - acc: 0.9470\n",
      "Epoch 67/150\n",
      "30065/30065 [==============================] - 1s 30us/step - loss: 0.1225 - acc: 0.9461\n",
      "Epoch 68/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1211 - acc: 0.9455\n",
      "Epoch 69/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1218 - acc: 0.9463\n",
      "Epoch 70/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1201 - acc: 0.9468\n",
      "Epoch 71/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1189 - acc: 0.9482\n",
      "Epoch 72/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1184 - acc: 0.9476\n",
      "Epoch 73/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1180 - acc: 0.9471\n",
      "Epoch 74/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1189 - acc: 0.9481\n",
      "Epoch 75/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1182 - acc: 0.9474\n",
      "Epoch 76/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1178 - acc: 0.9475\n",
      "Epoch 77/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1193 - acc: 0.9470\n",
      "Epoch 78/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1159 - acc: 0.9482\n",
      "Epoch 79/150\n",
      "30065/30065 [==============================] - ETA: 0s - loss: 0.1160 - acc: 0.948 - 1s 29us/step - loss: 0.1159 - acc: 0.9487\n",
      "Epoch 80/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1174 - acc: 0.9485\n",
      "Epoch 81/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1151 - acc: 0.9480\n",
      "Epoch 82/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1151 - acc: 0.9480\n",
      "Epoch 83/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1144 - acc: 0.9491\n",
      "Epoch 84/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1152 - acc: 0.9474\n",
      "Epoch 85/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1157 - acc: 0.9485\n",
      "Epoch 86/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1146 - acc: 0.9494\n",
      "Epoch 87/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1121 - acc: 0.9502\n",
      "Epoch 88/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1129 - acc: 0.9503\n",
      "Epoch 89/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1118 - acc: 0.9498\n",
      "Epoch 90/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1158 - acc: 0.9479\n",
      "Epoch 91/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1123 - acc: 0.9495\n",
      "Epoch 92/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1115 - acc: 0.9492\n",
      "Epoch 93/150\n",
      "30065/30065 [==============================] - 1s 32us/step - loss: 0.1109 - acc: 0.9504\n",
      "Epoch 94/150\n",
      "30065/30065 [==============================] - 1s 30us/step - loss: 0.1121 - acc: 0.9502\n",
      "Epoch 95/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1110 - acc: 0.9497\n",
      "Epoch 96/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1118 - acc: 0.9500\n",
      "Epoch 97/150\n",
      "30065/30065 [==============================] - 1s 27us/step - loss: 0.1092 - acc: 0.9505\n",
      "Epoch 98/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1090 - acc: 0.9501\n",
      "Epoch 99/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1118 - acc: 0.9498\n",
      "Epoch 100/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1102 - acc: 0.9490\n",
      "Epoch 101/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1102 - acc: 0.9511\n",
      "Epoch 102/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1075 - acc: 0.9519\n",
      "Epoch 103/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1097 - acc: 0.9502\n",
      "Epoch 104/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1071 - acc: 0.9514\n",
      "Epoch 105/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1078 - acc: 0.9508\n",
      "Epoch 106/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1091 - acc: 0.9514\n",
      "Epoch 107/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1078 - acc: 0.9510\n",
      "Epoch 108/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1071 - acc: 0.9508\n",
      "Epoch 109/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1085 - acc: 0.9512\n",
      "Epoch 110/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1075 - acc: 0.9515\n",
      "Epoch 111/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1063 - acc: 0.9521\n",
      "Epoch 112/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1084 - acc: 0.9511\n",
      "Epoch 113/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1095 - acc: 0.9503\n",
      "Epoch 114/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1048 - acc: 0.9522\n",
      "Epoch 115/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1054 - acc: 0.9526\n",
      "Epoch 116/150\n",
      "30065/30065 [==============================] - 474s 16ms/step - loss: 0.1059 - acc: 0.9526\n",
      "Epoch 117/150\n",
      "30065/30065 [==============================] - 2s 65us/step - loss: 0.1068 - acc: 0.9519\n",
      "Epoch 118/150\n",
      "30065/30065 [==============================] - 1s 34us/step - loss: 0.1050 - acc: 0.9527\n",
      "Epoch 119/150\n",
      "30065/30065 [==============================] - 1s 44us/step - loss: 0.1038 - acc: 0.9533\n",
      "Epoch 120/150\n",
      "30065/30065 [==============================] - 1s 35us/step - loss: 0.1054 - acc: 0.9517\n",
      "Epoch 121/150\n",
      "30065/30065 [==============================] - 1s 33us/step - loss: 0.1070 - acc: 0.9516\n",
      "Epoch 122/150\n",
      "30065/30065 [==============================] - 1s 30us/step - loss: 0.1046 - acc: 0.9528\n",
      "Epoch 123/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1039 - acc: 0.9536\n",
      "Epoch 124/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1061 - acc: 0.9520\n",
      "Epoch 125/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1048 - acc: 0.9525\n",
      "Epoch 126/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1030 - acc: 0.9523\n",
      "Epoch 127/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1028 - acc: 0.9521\n",
      "Epoch 128/150\n",
      "30065/30065 [==============================] - 1s 30us/step - loss: 0.1040 - acc: 0.9526\n",
      "Epoch 129/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1068 - acc: 0.9513\n",
      "Epoch 130/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1046 - acc: 0.9526\n",
      "Epoch 131/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1030 - acc: 0.9536\n",
      "Epoch 132/150\n",
      "30065/30065 [==============================] - 1s 28us/step - loss: 0.1049 - acc: 0.9516\n",
      "Epoch 133/150\n",
      "30065/30065 [==============================] - 1s 34us/step - loss: 0.1054 - acc: 0.9524\n",
      "Epoch 134/150\n",
      "30065/30065 [==============================] - 1s 31us/step - loss: 0.1039 - acc: 0.9533\n",
      "Epoch 135/150\n",
      "30065/30065 [==============================] - 1s 32us/step - loss: 0.1024 - acc: 0.9538\n",
      "Epoch 136/150\n",
      "30065/30065 [==============================] - 1s 32us/step - loss: 0.1025 - acc: 0.9534\n",
      "Epoch 137/150\n",
      "30065/30065 [==============================] - 1s 33us/step - loss: 0.1017 - acc: 0.9539\n",
      "Epoch 138/150\n",
      "30065/30065 [==============================] - 1s 32us/step - loss: 0.0995 - acc: 0.9548\n",
      "Epoch 139/150\n",
      "30065/30065 [==============================] - 1s 34us/step - loss: 0.1031 - acc: 0.9528\n",
      "Epoch 140/150\n",
      "30065/30065 [==============================] - 1s 32us/step - loss: 0.1037 - acc: 0.9528\n",
      "Epoch 141/150\n",
      "30065/30065 [==============================] - 1s 32us/step - loss: 0.1031 - acc: 0.9534\n",
      "Epoch 142/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.0999 - acc: 0.9542\n",
      "Epoch 143/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.1011 - acc: 0.9532\n",
      "Epoch 144/150\n",
      "30065/30065 [==============================] - 1s 31us/step - loss: 0.0997 - acc: 0.9544\n",
      "Epoch 145/150\n",
      "30065/30065 [==============================] - 1s 31us/step - loss: 0.1031 - acc: 0.9527\n",
      "Epoch 146/150\n",
      "30065/30065 [==============================] - 1s 30us/step - loss: 0.1013 - acc: 0.9542\n",
      "Epoch 147/150\n",
      "30065/30065 [==============================] - 1s 29us/step - loss: 0.0999 - acc: 0.9541\n",
      "Epoch 148/150\n",
      "30065/30065 [==============================] - 1s 30us/step - loss: 0.1016 - acc: 0.9543\n",
      "Epoch 149/150\n",
      "30065/30065 [==============================] - 1s 31us/step - loss: 0.1020 - acc: 0.9538\n",
      "Epoch 150/150\n",
      "30065/30065 [==============================] - 1s 32us/step - loss: 0.0996 - acc: 0.9547\n",
      "Epoch 1/150\n",
      "31647/31647 [==============================] - 2s 49us/step - loss: 0.3788 - acc: 0.8691\n",
      "Epoch 2/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.3130 - acc: 0.8847\n",
      "Epoch 3/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.2218 - acc: 0.8936\n",
      "Epoch 4/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.2052 - acc: 0.9014\n",
      "Epoch 5/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1987 - acc: 0.9029\n",
      "Epoch 6/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1953 - acc: 0.9077\n",
      "Epoch 7/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1921 - acc: 0.9091\n",
      "Epoch 8/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1896 - acc: 0.9102\n",
      "Epoch 9/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1891 - acc: 0.9099\n",
      "Epoch 10/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1867 - acc: 0.9111\n",
      "Epoch 11/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1845 - acc: 0.9116\n",
      "Epoch 12/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1835 - acc: 0.9119\n",
      "Epoch 13/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1824 - acc: 0.9127\n",
      "Epoch 14/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1815 - acc: 0.9142\n",
      "Epoch 15/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1793 - acc: 0.9148\n",
      "Epoch 16/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1783 - acc: 0.9145\n",
      "Epoch 17/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1768 - acc: 0.9145\n",
      "Epoch 18/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1752 - acc: 0.9165\n",
      "Epoch 19/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1742 - acc: 0.9158\n",
      "Epoch 20/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1731 - acc: 0.9177\n",
      "Epoch 21/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1727 - acc: 0.9172\n",
      "Epoch 22/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1710 - acc: 0.9173\n",
      "Epoch 23/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1710 - acc: 0.9170\n",
      "Epoch 24/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1692 - acc: 0.9191\n",
      "Epoch 25/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1679 - acc: 0.9188\n",
      "Epoch 26/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1681 - acc: 0.9195\n",
      "Epoch 27/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1667 - acc: 0.9190\n",
      "Epoch 28/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1655 - acc: 0.9205\n",
      "Epoch 29/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1642 - acc: 0.9210\n",
      "Epoch 30/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1637 - acc: 0.9214\n",
      "Epoch 31/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1626 - acc: 0.9219\n",
      "Epoch 32/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1620 - acc: 0.9223\n",
      "Epoch 33/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1605 - acc: 0.9233\n",
      "Epoch 34/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1608 - acc: 0.9224\n",
      "Epoch 35/150\n",
      "31647/31647 [==============================] - 1s 34us/step - loss: 0.1595 - acc: 0.9231\n",
      "Epoch 36/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1579 - acc: 0.9244\n",
      "Epoch 37/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1583 - acc: 0.9225\n",
      "Epoch 38/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1570 - acc: 0.9241\n",
      "Epoch 39/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1567 - acc: 0.9244\n",
      "Epoch 40/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1549 - acc: 0.9255\n",
      "Epoch 41/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1547 - acc: 0.9251\n",
      "Epoch 42/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1531 - acc: 0.9261\n",
      "Epoch 43/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1518 - acc: 0.9276\n",
      "Epoch 44/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1519 - acc: 0.9271\n",
      "Epoch 45/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1519 - acc: 0.9270\n",
      "Epoch 46/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1499 - acc: 0.9270\n",
      "Epoch 47/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1487 - acc: 0.9287\n",
      "Epoch 48/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1484 - acc: 0.9286\n",
      "Epoch 49/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1486 - acc: 0.9287\n",
      "Epoch 50/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1480 - acc: 0.9290\n",
      "Epoch 51/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1470 - acc: 0.9301\n",
      "Epoch 52/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1469 - acc: 0.9293\n",
      "Epoch 53/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1466 - acc: 0.9283\n",
      "Epoch 54/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1462 - acc: 0.9303\n",
      "Epoch 55/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1439 - acc: 0.9312\n",
      "Epoch 56/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1430 - acc: 0.9321\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1453 - acc: 0.9311\n",
      "Epoch 58/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1424 - acc: 0.9311\n",
      "Epoch 59/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1414 - acc: 0.9314\n",
      "Epoch 60/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1425 - acc: 0.9318\n",
      "Epoch 61/150\n",
      "31647/31647 [==============================] - ETA: 0s - loss: 0.1397 - acc: 0.933 - 1s 29us/step - loss: 0.1405 - acc: 0.9329\n",
      "Epoch 62/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1422 - acc: 0.9336\n",
      "Epoch 63/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1411 - acc: 0.9330\n",
      "Epoch 64/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1386 - acc: 0.9340\n",
      "Epoch 65/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1388 - acc: 0.9329\n",
      "Epoch 66/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1399 - acc: 0.9322\n",
      "Epoch 67/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1390 - acc: 0.9332\n",
      "Epoch 68/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1387 - acc: 0.9341\n",
      "Epoch 69/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1360 - acc: 0.9346\n",
      "Epoch 70/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1372 - acc: 0.9335\n",
      "Epoch 71/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1366 - acc: 0.9337\n",
      "Epoch 72/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1366 - acc: 0.9340\n",
      "Epoch 73/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1355 - acc: 0.9347\n",
      "Epoch 74/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1343 - acc: 0.9358\n",
      "Epoch 75/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1352 - acc: 0.9346\n",
      "Epoch 76/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1346 - acc: 0.9359\n",
      "Epoch 77/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1347 - acc: 0.9355\n",
      "Epoch 78/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1341 - acc: 0.9362\n",
      "Epoch 79/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1335 - acc: 0.9357\n",
      "Epoch 80/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1334 - acc: 0.9351\n",
      "Epoch 81/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1360 - acc: 0.9341\n",
      "Epoch 82/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1318 - acc: 0.9363\n",
      "Epoch 83/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1311 - acc: 0.9358\n",
      "Epoch 84/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1319 - acc: 0.9363\n",
      "Epoch 85/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1312 - acc: 0.9369\n",
      "Epoch 86/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1313 - acc: 0.9363\n",
      "Epoch 87/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1291 - acc: 0.9368\n",
      "Epoch 88/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1309 - acc: 0.9367\n",
      "Epoch 89/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1297 - acc: 0.9368\n",
      "Epoch 90/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1299 - acc: 0.9370\n",
      "Epoch 91/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1300 - acc: 0.9372\n",
      "Epoch 92/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1283 - acc: 0.9382\n",
      "Epoch 93/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1282 - acc: 0.9373\n",
      "Epoch 94/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1285 - acc: 0.9378\n",
      "Epoch 95/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1271 - acc: 0.9367\n",
      "Epoch 96/150\n",
      "31647/31647 [==============================] - 1s 33us/step - loss: 0.1280 - acc: 0.9389\n",
      "Epoch 97/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1251 - acc: 0.9388\n",
      "Epoch 98/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1281 - acc: 0.9380\n",
      "Epoch 99/150\n",
      "31647/31647 [==============================] - 1s 33us/step - loss: 0.1266 - acc: 0.9388\n",
      "Epoch 100/150\n",
      "31647/31647 [==============================] - ETA: 0s - loss: 0.1273 - acc: 0.937 - 1s 31us/step - loss: 0.1271 - acc: 0.9379\n",
      "Epoch 101/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1269 - acc: 0.9384\n",
      "Epoch 102/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1277 - acc: 0.9368\n",
      "Epoch 103/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1250 - acc: 0.9384\n",
      "Epoch 104/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1258 - acc: 0.9389\n",
      "Epoch 105/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1270 - acc: 0.9384\n",
      "Epoch 106/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1251 - acc: 0.9387\n",
      "Epoch 107/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1264 - acc: 0.9390\n",
      "Epoch 108/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1253 - acc: 0.9384\n",
      "Epoch 109/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1246 - acc: 0.9389\n",
      "Epoch 110/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1251 - acc: 0.9377\n",
      "Epoch 111/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1238 - acc: 0.9384\n",
      "Epoch 112/150\n",
      "31647/31647 [==============================] - 1s 35us/step - loss: 0.1233 - acc: 0.9393\n",
      "Epoch 113/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1233 - acc: 0.9390\n",
      "Epoch 114/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1234 - acc: 0.9385\n",
      "Epoch 115/150\n",
      "31647/31647 [==============================] - 1s 33us/step - loss: 0.1237 - acc: 0.9392\n",
      "Epoch 116/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1230 - acc: 0.9386\n",
      "Epoch 117/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1231 - acc: 0.9393\n",
      "Epoch 118/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1221 - acc: 0.9394\n",
      "Epoch 119/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1204 - acc: 0.9390\n",
      "Epoch 120/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1204 - acc: 0.9393\n",
      "Epoch 121/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1221 - acc: 0.9394\n",
      "Epoch 122/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1230 - acc: 0.9375\n",
      "Epoch 123/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1216 - acc: 0.9397\n",
      "Epoch 124/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1211 - acc: 0.9395\n",
      "Epoch 125/150\n",
      "31647/31647 [==============================] - 1s 33us/step - loss: 0.1210 - acc: 0.9403: 0s - loss: 0.1220 - acc:\n",
      "Epoch 126/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1205 - acc: 0.9405\n",
      "Epoch 127/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1220 - acc: 0.9390\n",
      "Epoch 128/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1198 - acc: 0.9405\n",
      "Epoch 129/150\n",
      "31647/31647 [==============================] - ETA: 0s - loss: 0.1196 - acc: 0.940 - 1s 32us/step - loss: 0.1200 - acc: 0.9401\n",
      "Epoch 130/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1201 - acc: 0.9401\n",
      "Epoch 131/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1196 - acc: 0.9407\n",
      "Epoch 132/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1180 - acc: 0.9414\n",
      "Epoch 133/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1204 - acc: 0.9385\n",
      "Epoch 134/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1189 - acc: 0.9406\n",
      "Epoch 135/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1191 - acc: 0.9400\n",
      "Epoch 136/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1213 - acc: 0.9400\n",
      "Epoch 137/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1182 - acc: 0.9404\n",
      "Epoch 138/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1197 - acc: 0.9411\n",
      "Epoch 139/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1186 - acc: 0.9408\n",
      "Epoch 140/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1176 - acc: 0.9395\n",
      "Epoch 141/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1185 - acc: 0.9406: 0s - loss: 0.1\n",
      "Epoch 142/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1207 - acc: 0.9396\n",
      "Epoch 143/150\n",
      "31647/31647 [==============================] - 1s 33us/step - loss: 0.1170 - acc: 0.9415\n",
      "Epoch 144/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1152 - acc: 0.9422\n",
      "Epoch 145/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1180 - acc: 0.9404\n",
      "Epoch 146/150\n",
      "31647/31647 [==============================] - 1s 32us/step - loss: 0.1179 - acc: 0.9416\n",
      "Epoch 147/150\n",
      "31647/31647 [==============================] - 1s 31us/step - loss: 0.1162 - acc: 0.9424\n",
      "Epoch 148/150\n",
      "31647/31647 [==============================] - 1s 29us/step - loss: 0.1163 - acc: 0.9408\n",
      "Epoch 149/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1179 - acc: 0.9403\n",
      "Epoch 150/150\n",
      "31647/31647 [==============================] - 1s 30us/step - loss: 0.1174 - acc: 0.9413\n"
     ]
    }
   ],
   "source": [
    "dnnkc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22152/22152 [==============================] - 0s 17us/step\n",
      "9495/9495 [==============================] - 0s 14us/step\n",
      "23735/23735 [==============================] - 0s 17us/step\n",
      "10173/10173 [==============================] - 0s 14us/step\n",
      "25317/25317 [==============================] - 0s 17us/step\n",
      "10851/10851 [==============================] - 0s 13us/step\n",
      "26900/26900 [==============================] - 0s 16us/step\n",
      "11529/11529 [==============================] - 0s 13us/step\n",
      "28482/28482 [==============================] - 0s 16us/step\n",
      "12207/12207 [==============================] - 0s 14us/step\n",
      "30065/30065 [==============================] - 0s 16us/step\n",
      "12885/12885 [==============================] - 0s 13us/step\n",
      "31647/31647 [==============================] - 0s 16us/step\n",
      "13564/13564 [==============================] - 0s 13us/step\n"
     ]
    }
   ],
   "source": [
    "lcdnnkc=dnnkc.getLearningCurves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2367d908>,\n",
       " <matplotlib.lines.Line2D at 0x1a2367def0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nECV9EZES8v8BMUDityQHkZsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a22bcf128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lcdnnkc[0,:],'b',lcdnnkc[1,:],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913299911706295"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnkc.getScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnnkc.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnnkc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initiating empty model DNNKC6. DNNClassificationKeras\n"
     ]
    }
   ],
   "source": [
    "recoveredDnnkc = DNNClassificationKerasDSBaseModel('DNNKC6',None,None,None,None,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recoveredDnnkc.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recoveredDnnkc.predict(X[510:515,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[510:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.88      1.00      0.94     11966\n",
      "        1.0       0.00      0.00      0.00      1598\n",
      "\n",
      "avg / total       0.78      0.88      0.83     13564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dnnkc.model.y_test,dnnkc.predict(dnnkc.model.X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11966     0]\n",
      " [ 1598     0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(dnnkc.model.y_test,dnnkc.predict(dnnkc.model.X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Evaluation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
